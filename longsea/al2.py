import functools
import math
import warnings
from io import BytesIO
import numpy as np
import openpyxl
import pandas as pd
import streamlit
from openpyxl.utils.dataframe import dataframe_to_rows
import zipfile
import re
from typing import Dict, Union, List, Any, Callable, Optional, Tuple, Literal
from openpyxl.workbook import Workbook
from openpyxl.worksheet.worksheet import Worksheet


'''
# 2024.07.08æ›´æ–°ï¼šå¯¹å¤šä¸ªå‡½æ•°è¿›è¡Œä¼˜åŒ–ã€‚
# 2024.11.04æ›´æ–°ï¼šå¯¹æ•´ä¸ªæ¨¡å—è¿›è¡Œé‡æ„ï¼Œå¢å¼ºAndfåŠŸèƒ½ï¼Œä¼˜åŒ–ç›¸å…³åŠŸèƒ½å‡½æ•°ã€‚
# 2024.11.24æ›´æ–°ï¼šå®Œæˆalsé‡æ„ï¼Œé‡å‘½åä¸ºalæ¨¡å—ã€‚
# 2025.02.01æ›´æ–°ï¼šæ·»åŠ äº†get_cls_score()æ–¹æ³•ï¼Œå®ç°äº†ç­çº§åˆ†æ-åˆ†æ•°æ®µåŠŸèƒ½ï¼›ç»™funs_fd()æ·»åŠ revå‚æ•°ã€‚
# 2025.09.15æ›´æ–°ï¼šä¿®æ”¹æ·»åŠ äº†å¤šä¸ªå‡½æ•°ï¼Œæ˜¯ä¸€æ¬¡å·¨å¤§çš„æå‡ã€‚
'''

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–       Andfç±»åŠå…¶æ–¹æ³•      â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# åˆ›å»ºAndfç±»,ä»¥ç”Ÿæˆå¤šç§æŠ¥è¡¨:ä¸¤ç‡ä¸€å¹³æŠ¥è¡¨,å­¦ç§‘åˆ†æ•°æ®µæŠ¥è¡¨,å­¦ç§‘åŒè¾¾æ ‡æŠ¥è¡¨,ç­çº§åæ¬¡æ®µæŠ¥è¡¨
class Andf:

    # æ ‡å‡†å­¦ç§‘ååˆ—è¡¨ï¼šself.__sbjï¼Œ           åŒ…æ‹¬æˆç»©è¡¨æ²¡æœ‰çš„å­¦ç§‘åã€‚
    # æ ‡å‡†å­¦ç§‘åå­—å…¸ï¼šself.__sbj_dicï¼Œ       æ ‡å‡†å­¦ç§‘åå¯¹åº”çš„å­—å…¸ã€‚
    # å·²ç”¨å­¦ç§‘ååˆ—è¡¨ï¼šself.__sbj_lstï¼Œ       æ‰€æœ‰å·²ç»ä½¿ç”¨çš„å­¦ç§‘ååˆ—è¡¨ã€‚
    # æ€»åˆ†ç­æ¬¡çº§æ¬¡æˆç»©å…¨è¡¨ï¼šself.__df         åŒ…æ‹¬æ€»åˆ†ã€ç­æ¬¡ã€çº§æ¬¡çš„æˆç»©è¡¨ã€‚
    def __init__(self, df: pd.DataFrame) -> None:

        self.__df = df
        # å£°æ˜æ ‡å‡†å­¦ç§‘ååˆ—è¡¨
        self.__sbj: List[str] = ["è¯­æ–‡", "æ•°å­¦", "è‹±è¯­", "ç‰©ç†", "åŒ–å­¦", "ç”Ÿç‰©", "æ”¿æ²»", "å†å²", "åœ°ç†"]
        # ç¡®å®šdfè¡¨å¯¹åº”çš„[å­¦ç§‘å]åˆ—è¡¨:__sbj_lst.
        self.__sbj_lst: List[str] = list(set(self.__sbj) & set(self.__df.columns))
        # ç¡®å®šdfè¡¨å¯¹åº”çš„{å­¦ç§‘åï¼šåºå·}å­—å…¸ï¼š__sbj_dicã€‚
        self.__sbj_dic: Dict[str, int] = {val: idx + 1 for idx, val in enumerate(self.__sbj)}
        # å¯¹å­¦ç§‘åˆ—è¡¨è¿›è¡Œæ’åºï¼Œæ’åºè§„åˆ™ä¸ºï¼šå­—å…¸ä¸­keyå¯¹åº”çš„å€¼ã€‚
        self.__sbj_lst.sort(key=lambda x: self.__sbj_dic[x])

        # ç¡®ä¿å­¦ç§‘æˆç»©åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹ï¼Œé¿å…åœ¨è®¡ç®—æ€»åˆ†æ—¶å‡ºç°ç±»å‹é”™è¯¯
        for subject in self.__sbj_lst:
            self.__df[subject] = pd.to_numeric(self.__df[subject], errors='coerce')
        
        # å¢åŠ æ€»åˆ†åˆ—ã€ç­æ¬¡ã€çº§æ¬¡åˆ—ï¼Œåˆ›å»ºåŸºç¡€dfå¯¹è±¡
        self.__df["æ€»åˆ†"] = df.loc[:, self.__sbj_lst].sum(axis=1, min_count=1)
        # å¢åŠ ç­æ¬¡åˆ—
        self.__df["ç­æ¬¡"] = df.groupby("ç­çº§")["æ€»åˆ†"].rank(ascending=False, method="min")
        # å¢åŠ çº§æ¬¡åˆ—
        self.__df["çº§æ¬¡"] = df["æ€»åˆ†"].rank(axis=0, ascending=False, method="min")

    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–    åŸºæœ¬ä¿¡æ¯è¡¨ï¼ˆå­¦ç§‘è¡¨ï¼Œå­¦ç§‘å­—å…¸ï¼Œå…¨ä¿¡æ¯è¡¨ï¼‰ â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # è·å–dfè¡¨å­˜åœ¨çš„æ ‡å‡†å­¦ç§‘ååˆ—è¡¨ï¼Œå·±æ­£ç¡®æ’åºã€‚
    def get_sbj_lst(self) -> List[str]:
        """
        è¿”å›å€¼ï¼šå­¦ç§‘åˆ—è¡¨ã€‚æ ‡å‡†å­¦ç§‘åç§°å¯¹åº”çš„åˆ—è¡¨ã€‚
        """
        # å¯¹å­¦ç§‘åˆ—è¡¨è¿›è¡Œæ’åºï¼Œæ’åºè§„åˆ™ä¸ºï¼šå­—å…¸ä¸­keyå¯¹åº”çš„å€¼ã€‚
        return self.__sbj_lst

    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # è·å–å­¦ç§‘å_æ’åºçš„å­—å…¸(å­¦ç§‘åï¼šåºå·)
    def get_sbj_dic(self) -> Dict[str, int]:
        """
        è¿”å›å€¼ï¼šå­¦ç§‘åï¼šæ’åºçš„å­—å…¸ã€‚æ ‡å‡†å­¦ç§‘åç§°å¯¹åº”çš„å­—å…¸("è¯­æ–‡":1ï¼Œ"æ•°å­¦":2ï¼Œ"è‹±è¯­":3ï¼Œ"ç‰©ç†":4ï¼Œ"åŒ–å­¦":5ï¼Œ"ç”Ÿç‰©":6ï¼Œ"æ”¿æ²»":7ï¼Œ"å†å²":8ï¼Œ"åœ°ç†":9)
        """
        return dict((key, self.__sbj_dic[key]) for key in self.__sbj_lst)

    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # è·å–å…¨éƒ¨ä¿¡æ¯çš„dfè¡¨
    def get_all(self) -> pd.DataFrame:
        """
        è¿”å›å¯¼å…¥åï¼Œæ·»åŠ æ€»åˆ†ã€ç­æ¬¡ã€æ ¡æ¬¡åˆ—åçš„DFè¡¨ã€‚
        :return: æ·»åŠ æ€»åˆ†ã€ç­æ¬¡ã€æ ¡æ¬¡åˆ—åçš„DFè¡¨ã€‚
        """
        return self.__df
    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–    åŸºç¡€æŠ¥è¡¨ï¼ˆéƒ¨åˆ†ä¿¡æ¯è¡¨ï¼Œåæ¬¡è¡¨ï¼Œå­¦ç§‘åŒè¾¾æ ‡è¡¨ï¼‰  â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # æŒ‰åˆ—ååˆ—è¡¨ä¸æœ€å¤§ç­æ¬¡è·å–éƒ¨åˆ†dfè¡¨
    def get_df(self,
               columns: Optional[List[str]] = None,   # ä¾‹ï¼š["ç­çº§", "å­¦å·", "å§“å",'æ•°å­¦']
               max_class_rank: int = 60               # è·å–ç­çº§åˆ†ææŠ¥è¡¨ä¸­æ—¶ï¼Œæœ€å¤§è®¡ç®—äººæ•°ã€‚
               ) -> pd.DataFrame:
        """
        è¿”å›å€¼ï¼šdfè¡¨ã€‚
        :param columns: åˆ—åï¼Œåˆ—è¡¨ã€‚
        :param max_class_rank: ç­çº§æ•°ï¼Œæ•´æ•°ã€‚é»˜è®¤40ã€‚
        :return: dfè¡¨ã€‚
        """
        if columns is None:
            columns = ["ç­çº§", "å­¦å·", "å§“å"]
        df = self.__df[self.__df["ç­æ¬¡"] <= max_class_rank]
        return df.loc[:, columns]

    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # è·å–åæ¬¡è¡¨ï¼ˆå­¦ç§‘åæ¬¡ï¼Œæ€»åˆ†åæ¬¡ï¼‰
    def get_mc(self,
               max_class_rank: int = None,     # è·å–ç­çº§åˆ†ææŠ¥è¡¨ä¸­æ—¶ï¼Œæœ€å¤§è®¡ç®—äººæ•°ã€‚
               combine_ranks: int = 1          # æ˜¯å¦åˆå¹¶å­¦ç§‘åæ¬¡ï¼Œæ€»åˆ†åæ¬¡ä¸ºå…ƒç»„ã€‚é»˜è®¤1ï¼šåˆå¹¶.
               ) -> pd.DataFrame:
        """
        è¿”å›ç­æ¬¡æ»¡è¶³å°äºmax_class_rankçš„dfè¡¨.å½“combine_ranks=1åˆå¹¶ç­æ¬¡ä¸æ€»åˆ†åæ¬¡ä¸ºä¸€ä¸ªå…ƒç»„
        :param max_class_rank: ç­çº§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤40,å–ç­æ¬¡<=40çš„æ•°æ®ã€‚
        :param combine_ranks: æ•´æ•°1æˆ–0ã€‚0,å„ç§‘ç‹¬ç«‹æ’åã€‚é»˜è®¤1,å­¦ç§‘æ’åä¸æ€»åˆ†æ’åç»„åˆä¸ºå…ƒç»„.
        :return: dfè¡¨ã€‚ç­æ¬¡æ»¡è¶³å°äºmax_class_rankçš„dfè¡¨.å½“combine_ranks=1åˆå¹¶ç­æ¬¡ä¸æ€»åˆ†åæ¬¡ä¸ºä¸€ä¸ªå…ƒç»„
        """
        if max_class_rank != None:
            df = self.__df[self.__df["ç­æ¬¡"] <= max_class_rank]
        else:
            df= self.__df.copy()
        df_mc = df_rank_cols(df, self.__sbj_lst+["æ€»åˆ†"], method='min', ascending=False)

        if combine_ranks == 1:
            df_mc = df_pair_cols(df_mc, self.__sbj_lst, 'æ€»åˆ†')

        return df_mc


    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # è·å–å­¦ç§‘åŒè¾¾æ ‡æŠ¥è¡¨
    def get_db(self,
               max_subject_rank: int = 40,
               max_total_rank: int = 40
               ) -> pd.DataFrame:
        """
        è¿”å›ç­çº§åˆ†ææŠ¥è¡¨.
        :param max_subject_rank: ç§‘ç›®æœ€å¤§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤40.
        :param max_total_rank: æ€»åˆ†æœ€å¤§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤40.
        :return: ç­çº§åˆ†ææŠ¥è¡¨.
        """
        # è·å–ç­çº§åæ¬¡ï¼ˆå­¦ç§‘åæ¬¡ï¼Œæ€»åˆ†åæ¬¡ï¼‰è¡¨ã€‚
        df_mc = self.get_mc(max_class_rank=None, combine_ranks=1)
        df_mc = df_mc[["ç­çº§"]+self.__sbj_lst]

        # è·å–å­¦ç§‘åŒè¾¾æ ‡å‡½æ•°åˆ—è¡¨
        func = functools.partial(count_dual_cond, a=max_subject_rank, b=max_total_rank)
        df_db = df_mc.groupby("ç­çº§").agg(func)

        return df_db

    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–    4å¤§æ ¸å¿ƒæŠ¥è¡¨ï¼ˆå¤šé˜ˆå€¼æŠ¥è¡¨ï¼‰â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # ç”Ÿæˆå­¦ç§‘å¤šé˜ˆå€¼åˆ†æ•°æ®µæŠ¥è¡¨.
    def get_fsd(self,
                dic_thresh_sbj: Dict[Tuple, List[str]],            # é˜ˆå€¼åˆ—è¡¨.å¦‚:[0,36,72,96,120]
                thresh_score: List[Union[int, float]] = None,      # ç§¯åˆ†åˆ—è¡¨.å¦‚:[10, 9, 2, 1, 0]
                max_class_rank: int = 60,       # ç­çº§æœ€å¤§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤40.
                add_rank_cols = 1                 # æ˜¯å¦åŠ å…¥æ±‚å„ï¼Œç‚¹ç§¯ã€æ’ååˆ—.
                ) -> Dict[Any, pd.DataFrame]:
        """
        ç”Ÿæˆåˆ†æ•°æ®µæŠ¥è¡¨.
        :param dic_val_sbj: é˜ˆå€¼åˆ—è¡¨.å¦‚:[0,36,72,96,120]
        :param thresh_score: å­¦ç§‘åæ¬¡æ®µé˜ˆå€¼åˆ—è¡¨å¯¹åº”ç§¯åˆ†.å¦‚:[10, 9, 2, 1, 0]
        :param max_class_rank: æœ€å¤§ç­æ¬¡,æ•´æ•°.å³ç­çº§æœ€å¤§å‚è¯„äººæ•°
        :return: åˆ†æ•°æ®µæŠ¥è¡¨.
        """
        # ç”Ÿæˆå­—å…¸{å­¦ç§‘:ï¼ˆ72ï¼Œ96ï¼Œ120ï¼‰}ï¼Œå¹¶æ’åº
        dic = dict_rev_sort(dic=dic_thresh_sbj, sort_order=self.__sbj_lst)

        # å®šä¹‰{å­¦ç§‘:[åˆ†æ•°æ®µå‡½æ•°ç»„]}å­—å…¸
        dic_FAN = {key: functools.partial(make_bin_counters, thresh=dic[key])() for key in dic.keys()}

        # è·å–dfè¡¨,è¦æ±‚æœ€å¤§ç­æ¬¡å°äºmax_class_rank,åˆ—ç´¢å¼•ä¸­æœ‰ç­çº§ä¸å­¦ç§‘å.
        df = self.get_df(columns=["ç­çº§"] + self.get_sbj_lst(), max_class_rank=max_class_rank)

        # æŒ‰ç­çº§åˆ†ç»„åï¼Œæ‰§è¡Œåˆ†æ•°æ®µå‡½æ•°ç»„ã€‚ç”Ÿæˆä¸€ä¸ªæŠ¥è¡¨.
        df_fsd = df.groupby("ç­çº§").agg(dic_FAN)

        # ä¾æ®ç¬¬0åˆ—ç´¢å¼•ï¼Œåˆ†å‰²æ•°æ®ä¸ºå¤šä¸ªdfè¡¨ã€‚
        df_fsd = df_split_levels(df_fsd)

        for key, dff in df_fsd.items():
            # æ·»åŠ å„åˆ†æ’åä¸‰åˆ—
            if thresh_score != None and  add_rank_cols == 1 :
                dff = df_add_rank(dff, lst=thresh_score, sum_col_name="ç§¯åˆ†", dot_col_name="ç‚¹ç§¯", rank_col_name="ç‚¹ç§¯æ’å")
            # æ·»åŠ è¡Œç´¢å¼•åç§°
            dff.index.name = key
            # æ›´æ–°å­—å…¸ä¸­çš„DataFrame
            df_fsd[key] = dff


        return df_fsd

    # ç”Ÿæˆå­¦ç§‘å¤šé˜ˆå€¼åŒè¾¾æ ‡æŠ¥è¡¨.
    def get_sdb(self,
                thresh: List[int],                              # é˜ˆå€¼åˆ—è¡¨.å¦‚:[0,200,260,300]
                thresh_score: List[Union[int, float]] = [10, 9, 2, 1, 0],     # ç§¯åˆ†åˆ—è¡¨.å¦‚:[10, 9, 2, 1, 0]
                max_class_rank: int = None,                       # ç­çº§æœ€å¤§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤60.
                max_total_rank: int = 200                       # å…¨æ ¡æœ€å¤§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤200.
                ) -> Dict[Any, pd.DataFrame]:
        """
        ç”ŸæˆåŒè¾¾æ ‡æŠ¥è¡¨.
        :param thresh: é˜ˆå€¼åˆ—è¡¨.å¦‚:[0,200,260,300]
        :param thresh_score: å­¦ç§‘åæ¬¡æ®µé˜ˆå€¼åˆ—è¡¨å¯¹åº”ç§¯åˆ†.å¦‚:[10, 9, 2, 1, 0]
        :param max_class_rank: æœ€å¤§ç­æ¬¡,æ•´æ•°.å³ç­çº§æœ€å¤§å‚è¯„äººæ•°
        :param max_total_rank: æœ€å¤§æ ¡æ¬¡.å³æœ€å¤§æ ¡æ¬¡,å¦‚:260
        :return: åŒè¾¾æ ‡æŠ¥è¡¨.
        """

        # è·å–ç­çº§åæ¬¡ï¼ˆå­¦ç§‘åæ¬¡ï¼Œæ€»åˆ†åæ¬¡ï¼‰è¡¨ã€‚
        df_mc = self.get_mc(max_class_rank=max_class_rank, combine_ranks=1)

        # è·å–å­¦ç§‘åŒè¾¾æ ‡å‡½æ•°åˆ—è¡¨
        mcd_funs = functools.partial(make_dual_cond_counters, thresh=thresh, sec_thresh=max_total_rank)

        # åˆ›å»ºå­—å…¸ï¼Œæ·»åŠ é”®å€¼å¯¹ä¸º{å­¦ç§‘åï¼šå•è¾¾æ ‡å‡½æ•°},ä»¥è®¡ç®—å•è¾¾æ ‡äººæ•°.
        dic_mcd_funs = {str(i): mcd_funs() for i in self.__sbj_lst}

        # ä½¿ç”¨èšåˆå‡½æ•°ï¼Œè®¡ç®—å­¦ç§‘åŒè¾¾æ ‡äººæ•°ï¼Œå¹¶è¿”å›dfè¡¨ã€‚
        df_SDB = df_mc.groupby("ç­çº§").agg(dic_mcd_funs)

        # ä¾æ®ç¬¬0åˆ—ç´¢å¼•ï¼Œåˆ†å‰²æ•°æ®ä¸ºå¤šä¸ªdfè¡¨ã€‚
        dfs_xk = df_split_levels(df_SDB)

        # æ·»åŠ å„ç§‘ç§¯åˆ†åˆ—
        if thresh_score != 0:
            for key, dff in dfs_xk.items():
                # æ·»åŠ å„åˆ†æ’åä¸‰åˆ—
                dff = df_add_rank(dff, lst=thresh_score, sum_col_name="ç§¯åˆ†", dot_col_name="ç‚¹ç§¯", rank_col_name="æ’å")
                # æ·»åŠ è¡Œç´¢å¼•åç§°
                dff.index.name = key
                # æ›´æ–°å­—å…¸ä¸­çš„DataFrame
                dfs_xk[key] = dff
        return dfs_xk

    # ç”Ÿæˆä¸¤ç‡ä¸€å¹³æŠ¥è¡¨.
    def get_lv(self,
               dic_total_sbj: Dict[int, List[str]],     #
               thresh: List[float] = [0.6, 0.8],        # é˜ˆå€¼åˆ—è¡¨.å¦‚:[0.6,0.8]
               max_class_rank: int = 40,                # ç­çº§æœ€å¤§åæ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤40.
               include_count_valid: int = 0,             # æ·»åŠ ç»Ÿè®¡æœ‰æ•ˆäººæ•°åˆ—ã€‚é»˜è®¤ä¸ç»Ÿè®¡ï¼š0ã€‚
               add_rank_cols= None,
               ) -> Dict[Any, pd.DataFrame]:
        """
        ç”Ÿæˆä¸¤ç‡ä¸€å¹³æŠ¥è¡¨.
        :param dic_total_sbj: {å­¦ç§‘ï¼šæ€»åˆ†}å­—å…¸ã€‚å¦‚:{120: ["è¯­æ–‡", "æ•°å­¦", "è‹±è¯­"], 70: ["ç‰©ç†", "æ”¿æ²»"], 50: ["åŒ–å­¦", "ç”Ÿç‰©", "å†å²", "åœ°ç†"]}
        :param calcu: 0æˆ–1ï¼Œé»˜è®¤1ã€‚0ï¼Œæ·»åŠ ã€‚1ï¼Œæ·»åŠ åˆ†æåˆ—ã€‚
        :param thresh: åŠæ ¼ç‡ä¼˜ç§€ç‡æˆ–å…¶å®ƒæ¯”ç‡çš„é˜ˆå€¼,ä¾‹[0.6,0.8]
        :param max_class_rank: æœ€å¤§ç­æ¬¡æ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤40,å–ç­æ¬¡<=40çš„æ•°æ®ã€‚
        :return: dfè¡¨ã€‚
        """

        # ä½¿ç”¨å­—å…¸æ¨å¯¼å¼è½¬æ¢ä¸º{å­¦ç§‘:æ€»åˆ†}å­—å…¸
        dic = dict_rev_sort(dic=dic_total_sbj, sort_order=self.__sbj_lst)

        # å®šä¹‰{å­¦ç§‘:[ä¸¤ç‡ä¸€å¹³å‡½æ•°ç»„]}å­—å…¸
        # æ˜ç¡®è®¾ç½® include_mean=True
        dic_FAN = {key: functools.partial(make_rate_counters,
                                          thresh=np.array(thresh + [1]) * val,
                                          include_count_valid=include_count_valid,
                                          include_mean=True)() for key, val in dic.items()}

        # è·å–éœ€è¿›è¡Œä¸¤ç‡ä¸€å¹³çš„dfè¡¨,è¦æ±‚æœ€å¤§ç­æ¬¡å°äºmax_class_rank,åˆ—ç´¢å¼•ä¸­äººç­çº§ä¸å­¦ç§‘å.
        df = self.get_df(columns=["ç­çº§"] + self.get_sbj_lst(), max_class_rank=max_class_rank)

        # æŒ‰ç­çº§åˆ†ç»„åï¼Œæ‰§è¡Œä¸¤ç‡ä¸€å¹³è®¡ç®—ã€‚ç”Ÿæˆä¸€ä¸ªæŠ¥è¡¨.
        df_lv = df.groupby("ç­çº§").agg(dic_FAN)

        # ä¾æ®ç¬¬0åˆ—ç´¢å¼•ï¼Œåˆ†å‰²æ•°æ®ä¸ºå¤šä¸ªdfè¡¨ã€‚
        dfs_lv = df_split_levels(df_lv)

        # åŠ å…¥æ’ååˆ—
        if add_rank_cols !=None:
            for key, dff in dfs_lv.items():
                dfs_lv[key] = df_add_cols_rank(dff, columns_to_rank=add_rank_cols)

        return dfs_lv

    # ç”Ÿæˆç­çº§åˆ†ææŠ¥è¡¨-å„æ¬¡æ®µç»Ÿè®¡
    def get_cls(self,
                thresh: List[int],
                thresh_score: List[Union[int, float]] = None,
                max_class_rank: int = 60,
                cumu: int = 0,
                mode: int = 1
                ) -> pd.DataFrame:
        """
        è·å–ç­çº§åˆ†ææŠ¥è¡¨-å„æ¬¡æ®µç»Ÿè®¡ã€‚
        :param thresh: åæ¬¡æ®µé˜ˆå€¼åˆ—è¡¨ï¼Œåˆ—è¡¨ã€‚é»˜è®¤[0,100,200,300]ã€‚
        :param thresh_score: åæ¬¡æ®µç§¯åˆ†åˆ—è¡¨ï¼Œåˆ—è¡¨ã€‚é»˜è®¤[4,3,2,1]ã€‚
        :param max_class_rank: æœ€å¤§ç­çº§æ¬¡ï¼Œæ•´æ•°ã€‚é»˜è®¤60ã€‚
        :param cumu:  ç´¯è®¡å¼€å…³ï¼š0ä¸ºä¸ç´¯è®¡ï¼Œ1ä¸ºç´¯è®¡ã€‚
        :param mode: åŒºé—´æ¨¡å¼ï¼š0 ä¸ºå‰é—­åå¼€ï¼Œ1ä¸ºå‰å¼€åé—­ã€‚
        :return: dfè¡¨ã€‚ç­çº§åˆ†ææŠ¥è¡¨ã€‚
        """

        # å®šä¹‰åå‡½æ•°ï¼Œè®¾ç½®é˜ˆå€¼åˆ—è¡¨ï¼Œè‹¥ä¸º0ï¼Œåˆ™é»˜è®¤ä¸º[0,200,400]ã€‚cumu:0ä¸ºä¸ç´¯è®¡ï¼Œ1ä¸ºç´¯è®¡ã€‚
        funs_cls = functools.partial(make_bin_counters, thresh=thresh, cumu=cumu, mode=mode)

        # è·å–ç­çº§åæ¬¡è¡¨["ç­çº§"ï¼Œ"çº§æ¬¡"]
        df_cls = self.get_df(columns=["ç­çº§", "çº§æ¬¡"], max_class_rank=max_class_rank)
        # æŒ‰ç­çº§åˆ†ç»„åï¼Œæ‰§è¡Œç­çº§åæ¬¡è®¡ç®—ã€‚ç”Ÿæˆä¸€ä¸ªæŠ¥è¡¨.
        df_cls = df_cls.groupby("ç­çº§")["çº§æ¬¡"].agg(funs_cls())

        if thresh_score is not None:
            # æ·»åŠ å„åˆ†æ’åä¸‰åˆ—
            df_cls = df_add_rank(df_cls, lst=thresh_score, sum_col_name="æ€»äººæ•°", dot_col_name="ç‚¹ç§¯", rank_col_name="æ’å")
        return df_cls

    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–    ç»„åˆæŠ¥è¡¨ï¼ˆåŸºæœ¬æŠ¥è¡¨+æ ¸å¿ƒæŠ¥è¡¨ï¼‰ â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    # â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
    def get_db_fsd(self,
                   dic_thresh_sbj: Dict[Tuple, List[str]],  # é˜ˆå€¼åˆ—è¡¨.å¦‚:[0,36,72,96,120]
                   thresh_score: List[Union[int, float]] = None,  # ç§¯åˆ†åˆ—è¡¨.å¦‚:[10, 9, 2, 1, 0]
                   max_subject_rank: int = 40,
                   max_total_rank: int = 40
                   )->  Dict[Any, pd.DataFrame]:

        # è·å–å­¦ç§‘è¾¾æ ‡è¡¨
        df_db = self.get_db( max_subject_rank=max_subject_rank, max_total_rank=max_total_rank)
        fsd_df = self.get_fsd(dic_thresh_sbj=dic_thresh_sbj,thresh_score=thresh_score,add_rank_cols=0)
        for key,dff in fsd_df.items():
            dff.insert(0, 'åŒè¾¾æ ‡<='+ str(max_subject_rank), df_db[key])
            dff = df_add_rank(dff, lst=thresh_score, sum_col_name="ç§¯åˆ†", dot_col_name="ç‚¹ç§¯", rank_col_name="æ’å")
            fsd_df[key] = dff
        return fsd_df


# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–    å››å¤§åˆ†æå‡½æ•°ï¼ˆç»„ï¼‰å•å…ƒ   â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# ç»Ÿè®¡ Series ä¸­åŒæ—¶æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶çš„å…ƒç´ ä¸ªæ•°
def count_dual_cond(
        sr: pd.Series,
        a: Union[int, float],
        b: Union[int, float],
        op1: str = 'le',
        op2: str = 'le') -> int:
    """
    2025.09.18 ä¿®æ”¹.æ¥æºäºfun_sdb.
    ğŸ“Š ç»Ÿè®¡ Series ä¸­åŒæ—¶æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶çš„å…ƒç´ ä¸ªæ•°ã€‚
    æ¯ä¸ªå…ƒç´ ä¸º (x, y) äºŒå…ƒç»„ï¼Œç»Ÿè®¡æ»¡è¶³ x â—1 a ä¸” y â—2 b çš„ä¸ªæ•°ã€‚

    ğŸ“Œ æ”¯æŒæ“ä½œç¬¦ï¼š
        'le' â†’ <= ï¼ˆé»˜è®¤ï¼Œè¶Šå°è¶Šå¥½ï¼Œå¦‚æ’åï¼‰
        'ge' â†’ >= ï¼ˆè¶Šå¤§è¶Šå¥½ï¼Œå¦‚åˆ†æ•°ï¼‰
        'lt' â†’ <  ï¼ˆä¸¥æ ¼å°äºï¼‰
        'gt' â†’ >  ï¼ˆä¸¥æ ¼å¤§äºï¼‰

    ğŸ“ å‚æ•°ï¼š
        sr (pd.Series): å…ƒç´ ä¸º (x, y) äºŒå…ƒç»„çš„ Series
        a (Real): ç¬¬ä¸€ä¸ªæ¡ä»¶çš„é˜ˆå€¼
        b (Real): ç¬¬äºŒä¸ªæ¡ä»¶çš„é˜ˆå€¼
        op1 (str): x çš„æ¯”è¾ƒæ“ä½œç¬¦ï¼Œé»˜è®¤ 'le'
        op2 (str): y çš„æ¯”è¾ƒæ“ä½œç¬¦ï¼Œé»˜è®¤ 'le'

    ğŸ“¤ è¿”å›ï¼š
        int: åŒæ—¶æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶çš„å…ƒç´ ä¸ªæ•°

    ğŸ§ª ç¤ºä¾‹ï¼š
        sr = pd.Series([(1,11), (2,22), (3,33), (4,44)])
        count_dual_cond(sr, 3, 33, op1='le', op2='le')  # è¿”å› 3 â†’ (1,11), (2,22), (3,33)
        count_dual_cond(sr, 3, 33, op1='ge', op2='ge')  # è¿”å› 2 â†’ (3,33), (4,44)

    ğŸš¨ å¼‚å¸¸ï¼š
        ValueError: å½“å‚æ•°ä¸ç¬¦åˆè¦æ±‚æ—¶
        TypeError: å½“å‚æ•°ç±»å‹ä¸æ­£ç¡®æ—¶
    """
    # === ğŸš¦ é˜¶æ®µ1ï¼šåŸºç¡€ç±»å‹æ ¡éªŒ ===
    # 1. éªŒè¯ sr ç±»å‹
    if not isinstance(sr, pd.Series):
        raise TypeError("sr å¿…é¡»æ˜¯ pd.Series ç±»å‹")

    # 2. éªŒè¯ a å’Œ b ç±»å‹
    if not isinstance(a, (int, float)):
        raise TypeError("a å¿…é¡»æ˜¯æ•°å€¼ç±»å‹ï¼ˆint æˆ– floatï¼‰")
    if not isinstance(b, (int, float)):
        raise TypeError("b å¿…é¡»æ˜¯æ•°å€¼ç±»å‹ï¼ˆint æˆ– floatï¼‰")

    # 3. éªŒè¯ a å’Œ b å€¼
    if np.isnan(a) or np.isnan(b):
        raise ValueError("a å’Œ b ä¸èƒ½ä¸º NaN")
    if np.isinf(a) or np.isinf(b):
        raise ValueError("a å’Œ b ä¸èƒ½ä¸ºæ— ç©·å¤§")

    # 4. éªŒè¯ op1 å’Œ op2 ç±»å‹
    if not isinstance(op1, str):
        raise TypeError("op1 å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
    if not isinstance(op2, str):
        raise TypeError("op2 å¿…é¡»æ˜¯å­—ç¬¦ä¸²")

    # === ğŸ§® é˜¶æ®µ2ï¼šå®šä¹‰æ“ä½œç¬¦æ˜ å°„ + æ ¡éªŒæ“ä½œç¬¦åˆæ³•æ€§ ===
    op_map = {
        'le': lambda x, t: x <= t,  # å°äºç­‰äº
        'ge': lambda x, t: x >= t,  # å¤§äºç­‰äº
        'lt': lambda x, t: x < t,  # å°äº
        'gt': lambda x, t: x > t  # å¤§äº
    }

    if op1 not in op_map:
        raise ValueError(f"op1 å¿…é¡»æ˜¯ 'le', 'ge', 'lt', 'gt' ä¹‹ä¸€ï¼Œå½“å‰å€¼: {op1}")
    if op2 not in op_map:
        raise ValueError(f"op2 å¿…é¡»æ˜¯ 'le', 'ge', 'lt', 'gt' ä¹‹ä¸€ï¼Œå½“å‰å€¼: {op2}")

    # === ğŸ“‹ é˜¶æ®µ3ï¼šæ•°æ®å†…å®¹æ ¡éªŒ ===
    if len(sr) == 0:
        return 0

    # è¿‡æ»¤æ‰åŒ…å« NaN æˆ–æ— ç©·å¤§çš„å…ƒç´ 
    valid_items = []
    for i, item in enumerate(sr):
        # æ£€æŸ¥æ˜¯å¦ä¸ºå…ƒç»„
        if not isinstance(item, tuple):
            raise ValueError(f"Series ä¸­æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯å…ƒç»„ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ {type(item).__name__}")

        # æ£€æŸ¥å…ƒç»„é•¿åº¦
        if len(item) != 2:
            raise ValueError(f"Series ä¸­æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯é•¿åº¦ä¸º2çš„å…ƒç»„ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ é•¿åº¦ä¸º {len(item)}")

        # æ£€æŸ¥å…ƒç»„å…ƒç´ ç±»å‹
        x, y = item
        if not isinstance(x, (int, float)):
            raise ValueError(f"Series ä¸­æ¯ä¸ªå…ƒç´ çš„ç¬¬ä¸€ä¸ªå€¼å¿…é¡»æ˜¯æ•°å­—ï¼Œä½†ç´¢å¼• {i} çš„ç¬¬ä¸€ä¸ªå€¼æ˜¯ {type(x).__name__}")
        if not isinstance(y, (int, float)):
            raise ValueError(f"Series ä¸­æ¯ä¸ªå…ƒç´ çš„ç¬¬äºŒä¸ªå€¼å¿…é¡»æ˜¯æ•°å­—ï¼Œä½†ç´¢å¼• {i} çš„ç¬¬äºŒä¸ªå€¼æ˜¯ {type(y).__name__}")

        # æ£€æŸ¥å…ƒç»„å…ƒç´ å€¼ï¼Œè·³è¿‡åŒ…å« NaN æˆ–æ— ç©·å¤§çš„å…ƒç´ 
        if np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y):
            continue  # è·³è¿‡åŒ…å«æ— æ•ˆå€¼çš„å…ƒç´ 

        valid_items.append(item)

    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¿”å› 0
    if not valid_items:
        return 0

    # === ğŸš€ é˜¶æ®µ4ï¼šæ‰§è¡Œè®¡ç®—ï¼ˆNumPy å‘é‡åŒ–ï¼Œé«˜æ€§èƒ½ï¼‰===
    try:
        arr = np.array(valid_items)  # è½¬ä¸ºäºŒç»´æ•°ç»„ (n, 2)
        mask = op_map[op1](arr[:, 0], a) & op_map[op2](arr[:, 1], b)  # æ„å»ºå¸ƒå°”æ©ç 
        return int(np.sum(mask))  # ç»Ÿè®¡ True çš„ä¸ªæ•°å¹¶è¿”å› Python int
    except Exception as e:
        raise RuntimeError(f"è®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}") from e

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# ç”Ÿæˆä¸€ç»„æŒ‰æ•°å€¼åŒºé—´ï¼ˆbinï¼‰è¿›è¡Œè®¡æ•°çš„å‡½æ•°ï¼Œæ”¯æŒæ»‘åŠ¨åŒºé—´ä¸ç´¯è®¡åŒºé—´ã€å‰é—­åå¼€ä¸å‰å¼€åé—­æ¨¡å¼ã€‚
def make_bin_counters(
        thresh: Union[List[Union[int, float]], Tuple[Union[int, float], ...]],
        cumu: int = 0,
        mode: int = 0
        ) -> List[Callable]:
    """
    2025.09.18ä¿®æ”¹ï¼Œæ¥æºäºfuns_fd.
    ç”Ÿæˆä¸€ç»„æŒ‰æ•°å€¼åŒºé—´ï¼ˆbinï¼‰è¿›è¡Œè®¡æ•°çš„å‡½æ•°ï¼Œæ”¯æŒæ»‘åŠ¨åŒºé—´ä¸ç´¯è®¡åŒºé—´ã€å‰é—­åå¼€ä¸å‰å¼€åé—­æ¨¡å¼ã€‚

    ğŸ“Š å…¸å‹åº”ç”¨åœºæ™¯ï¼š
      - æˆç»©åˆ†ç»„ç»Ÿè®¡ï¼ˆæ¨è cumu=0, mode=0ï¼‰ï¼š
          Count[0-60)   â†’ ä¸åŠæ ¼äººæ•°
          Count[60-80)  â†’ åŠæ ¼äººæ•°
          Count[80-100) â†’ è‰¯å¥½äººæ•°
          Count[100-inf)â†’ ä¼˜ç§€äººæ•°

      - åæ¬¡ç´¯è®¡ç»Ÿè®¡ï¼ˆæ¨è cumu=1, mode=1ï¼‰ï¼š
          Count(0-60]   â†’ å‰60åäººæ•°
          Count(0-80]   â†’ å‰80åäººæ•°
          Count(0-100]  â†’ å‰100åäººæ•°
          Count(100-inf]â†’ 100åä¹‹åäººæ•°

    âš™ï¸ å‚æ•°è¯´æ˜ï¼š
      :param thresh: list or tuple
          åŒºé—´åˆ’åˆ†é˜ˆå€¼åˆ—è¡¨ï¼Œä¾‹å¦‚ [0, 60, 80, 100]ã€‚
          - è‡³å°‘éœ€è¦2ä¸ªå…ƒç´ 
          - è‡ªåŠ¨æ’åºï¼ˆä¸å½±å“åŸå§‹æ•°æ®ï¼‰
          - æœ€åä¸€ä¸ªåŒºé—´é»˜è®¤å»¶ä¼¸è‡³æ— ç©·å¤§ï¼ˆinfï¼‰

      :param cumu: int, default=0
          æ§åˆ¶åŒºé—´ç”Ÿæˆæ–¹å¼ï¼š
          0 â†’ æ»‘åŠ¨åŒºé—´ï¼ˆäº’æ–¥åˆ†æ®µï¼‰: [a0,a1), [a1,a2), [a2,a3), ...
          1 â†’ å›ºå®šèµ·ç‚¹ç´¯è®¡ + æœ€åç‹¬ç«‹åŒºé—´: [a0,a1), [a0,a2), ..., [a_last, inf)

      :param mode: int, default=0
          æ§åˆ¶åŒºé—´å¼€é—­è§„åˆ™ï¼š
          0 â†’ å‰é—­åå¼€ [a, b) â€”â€” æ¨èç”¨äºæˆç»©ã€å¹´é¾„ã€é‡‘é¢ç­‰è¿ç»­æ•°å€¼
          1 â†’ å‰å¼€åé—­ (a, b] â€”â€” æ¨èç”¨äºåæ¬¡ã€æ’åã€åºå·ç­‰ç¦»æ•£åºæ•°

    ğŸ¯ è¿”å›å€¼ï¼š
      :return: list of functions
          æ¯ä¸ªå‡½æ•°æ¥å— array/list è¾“å…¥ï¼Œè¿”å›æ»¡è¶³å¯¹åº”åŒºé—´çš„å…ƒç´ ä¸ªæ•°ã€‚
          å‡½æ•°åæ ¼å¼ï¼šCount[lower-upper) æˆ– Count(lower-upper]

    ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š
        data = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]

        # æˆç»©åˆ†ç»„
        counters = make_bin_counters([0,60,80,100], cumu=0, mode=0)
        for c in counters:
            print(f"{c.__name__}: {c(data)}")

        # åæ¬¡ç´¯è®¡
        counters = make_bin_counters([0,60,80,100], cumu=1, mode=1)
        for c in counters:
            print(f"{c.__name__}: {c(data)}")
    """
    # ========== å‚æ•°éªŒè¯ ==========
    # 1. éªŒè¯ thresh ç±»å‹
    if not isinstance(thresh, (list, tuple)):
        raise TypeError(f"å‚æ•° 'thresh' å¿…é¡»æ˜¯ list æˆ– tupleï¼Œå½“å‰ç±»å‹: {type(thresh).__name__}")

    # 2. éªŒè¯ thresh é•¿åº¦
    if len(thresh) < 2:
        raise ValueError(f"å‚æ•° 'thresh' è‡³å°‘éœ€è¦2ä¸ªé˜ˆå€¼ï¼Œå½“å‰: {len(thresh)}")

    # 3. éªŒè¯ thresh å…ƒç´ ç±»å‹å’Œå€¼
    for i, x in enumerate(thresh):
        if not isinstance(x, (int, float)):
            raise TypeError(f"thresh ä¸­çš„å…ƒç´ å¿…é¡»ä¸ºæ•°å­—ï¼ˆint/floatï¼‰ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ {type(x).__name__}")
        if math.isnan(x):
            raise ValueError(f"thresh ä¸­çš„å…ƒç´ ä¸èƒ½ä¸º NaNï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ NaN")
        if math.isinf(x):
            raise ValueError(f"thresh ä¸­çš„å…ƒç´ ä¸èƒ½ä¸ºæ— ç©·å¤§ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ {x}")

    # 4. éªŒè¯ cumu ç±»å‹å’Œå€¼
    if not isinstance(cumu, int):
        raise TypeError(f"å‚æ•° 'cumu' å¿…é¡»æ˜¯æ•´æ•°ï¼Œå½“å‰ç±»å‹: {type(cumu).__name__}")
    if cumu not in (0, 1):
        raise ValueError(f"å‚æ•° 'cumu' å¿…é¡»æ˜¯ 0 æˆ– 1ï¼Œå½“å‰å€¼: {cumu}")

    # 5. éªŒè¯ mode ç±»å‹å’Œå€¼
    if not isinstance(mode, int):
        raise TypeError(f"å‚æ•° 'mode' å¿…é¡»æ˜¯æ•´æ•°ï¼Œå½“å‰ç±»å‹: {type(mode).__name__}")
    if mode not in (0, 1):
        raise ValueError(f"å‚æ•° 'mode' å¿…é¡»æ˜¯ 0 æˆ– 1ï¼Œå½“å‰å€¼: {mode}")

    # 6. éªŒè¯ thresh æ˜¯å¦æœ‰é‡å¤å€¼
    if len(set(thresh)) != len(thresh):
        raise ValueError("thresh ä¸­åŒ…å«é‡å¤å€¼")

    # æ’åºï¼ˆä¸å½±å“åŸå§‹æ•°æ®ï¼‰
    thresh_sorted = sorted(thresh)
    if thresh_sorted != list(thresh):
        print(f"âš ï¸  è­¦å‘Š: thresh å·²è‡ªåŠ¨æ’åºï¼ˆåŸ: {thresh} â†’ ç°: {thresh_sorted}ï¼‰")
    thresh = thresh_sorted

    base = thresh[0]
    intervals = []

    if cumu == 1:
        # å›ºå®šèµ·ç‚¹ç´¯è®¡ï¼šå¯¹æ¯ä¸ª thresh[1:] ç”Ÿæˆç´¯è®¡åŒºé—´ [base, t)
        for t in thresh[1:]:
            intervals.append((base, t))
        # é¢å¤–è¿½åŠ æœ€åä¸€ä¸ªç‹¬ç«‹åŒºé—´ [last, inf)
        intervals.append((thresh[-1], float('inf')))
    else:  # cumu == 0ï¼Œé»˜è®¤æ»‘åŠ¨åŒºé—´
        thresh_ext = thresh + [float('inf')]
        intervals = [(thresh_ext[i], thresh_ext[i + 1]) for i in range(len(thresh_ext) - 1)]

    def make_counter(lower, upper):
        def counter(arr):
            # å¤„ç† pandas Series å¯¹è±¡
            if isinstance(arr, pd.Series):
                # æ£€æŸ¥ Series æ˜¯å¦ä¸ºç©º
                if arr.empty:
                    return 0
                # è½¬æ¢ä¸º numpy æ•°ç»„
                arr = arr.values
            # éªŒè¯è¾“å…¥æ•°æ®
            elif not isinstance(arr, (list, tuple, np.ndarray)):
                raise TypeError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯åˆ—è¡¨ã€å…ƒç»„ã€numpy æ•°ç»„æˆ– pandas Series")

            # è½¬æ¢ä¸º numpy æ•°ç»„
            arr = np.asarray(arr)

            # éªŒè¯æ•°ç»„å…ƒç´ ç±»å‹
            if not np.issubdtype(arr.dtype, np.number):
                raise TypeError("è¾“å…¥æ•°ç»„ä¸­çš„æ‰€æœ‰å…ƒç´ å¿…é¡»æ˜¯æ•°å­—ç±»å‹")

            # è¿‡æ»¤æ‰ NaN å€¼ï¼Œåªå¤„ç†æœ‰æ•ˆæ•°å€¼
            valid_arr = arr[~np.isnan(arr)]

            # æ£€æŸ¥æ˜¯å¦æœ‰æ— ç©·å¤§å€¼
            if np.any(np.isinf(valid_arr)):
                raise ValueError("è¾“å…¥æ•°ç»„ä¸­åŒ…å«æ— ç©·å¤§å€¼")

            # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¿”å›0
            if len(valid_arr) == 0:
                return 0

            # æ ¹æ®æ¨¡å¼è®¡ç®—è®¡æ•°
            if cumu == 1 and upper != float('inf'):
                # ç´¯è®¡åŒºé—´éƒ¨åˆ†
                if mode == 0:
                    return np.sum((valid_arr >= lower) & (valid_arr < upper))
                else:
                    return np.sum((valid_arr > lower) & (valid_arr <= upper))
            else:
                # æ»‘åŠ¨åŒºé—´ æˆ– æœ€åç‹¬ç«‹åŒºé—´
                if mode == 0:
                    return np.sum((valid_arr >= lower) & (valid_arr < upper))
                else:
                    return np.sum((valid_arr > lower) & (valid_arr <= upper))

        # ========== å‡½æ•°å‘½åï¼šç»Ÿä¸€ä½¿ç”¨ "Count[...)" æˆ– "Count(...]" ==========
        left_bracket = '[' if mode == 0 else '('
        right_bracket = ')' if mode == 0 else ']'

        # å¤„ç†æ— ç©·å¤§çš„æ˜¾ç¤º
        if math.isinf(upper):
            upper_display = "inf"
        else:
            upper_display = upper

        counter.__name__ = f"Count{left_bracket}{lower}-{upper_display}{right_bracket}"
        return counter

    return [make_counter(l, u) for l, u in intervals]

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# ç”Ÿæˆä¸€ç»„"åŒæ¡ä»¶è®¡æ•°å™¨"(Dual Condition Counters)ï¼Œæ”¯æŒåæ¬¡æ¨¡å¼ä¸åˆ†æ•°æ¨¡å¼ã€‚
def make_dual_cond_counters(
        thresh: Union[List[Union[int, float]], Tuple[Union[int, float], ...]],
        sec_thresh: Union[int, float],
        mode: str = 'rank'
        ) -> List[Callable]:
    """
    ç”Ÿæˆä¸€ç»„"åŒæ¡ä»¶è®¡æ•°å™¨"(Dual Condition Counters)ï¼Œæ”¯æŒåæ¬¡æ¨¡å¼ä¸åˆ†æ•°æ¨¡å¼ã€‚

    ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
      - æ¯ä¸ªå‡½æ•°ç»Ÿè®¡ï¼šä¸»ç»´åº¦è½åœ¨æŸåŒºé—´å†… ä¸” æ¬¡ç»´åº¦æ»¡è¶³é˜ˆå€¼æ¡ä»¶ çš„è®°å½•æ•°
      - é¢å¤–ç»Ÿè®¡ï¼šæ¬¡ç»´åº¦ä¸æ»¡è¶³é˜ˆå€¼æ¡ä»¶çš„è®°å½•æ•°ï¼ˆä¸»ç»´åº¦ä¸é™ï¼‰

    ğŸ“Š å…¸å‹åº”ç”¨åœºæ™¯ï¼š

      ğŸ“ åæ¬¡æ¨¡å¼ (mode='rank')ï¼š
        - ç»Ÿè®¡"å­¦ç§‘åæ¬¡åœ¨(0,60] ä¸” æ€»åˆ†åæ¬¡â‰¤100"çš„å­¦ç”Ÿ
        - é€‚ç”¨äºï¼šåæ¬¡è¶Šå°è¶Šå¥½ï¼ˆå¦‚æ’åï¼‰

      ğŸ“ˆ åˆ†æ•°æ¨¡å¼ (mode='score')ï¼š
        - ç»Ÿè®¡"æ•°å­¦åˆ†æ•°åœ¨[80,90) ä¸” æ€»åˆ†â‰¥450"çš„å­¦ç”Ÿ
        - é€‚ç”¨äºï¼šåˆ†æ•°è¶Šå¤§è¶Šå¥½ï¼ˆå¦‚æˆç»©ã€è¯„åˆ†ã€é”€å”®é¢ï¼‰

    âš™ï¸ å‚æ•°è¯´æ˜ï¼š
      :param thresh: list or tuple of numbers
          ä¸»ç»´åº¦åˆ†æ®µé˜ˆå€¼ï¼Œå¦‚ [0, 60, 80, 100] æˆ– [60, 70, 80, 90]ã€‚
          - è‡ªåŠ¨å‡åºæ’åºï¼ˆä¸å½±å“åŸå§‹æ•°æ®ï¼‰
          - è‡³å°‘éœ€è¦2ä¸ªå…ƒç´ 
          - æ”¯æŒ int/floatï¼Œè‡ªåŠ¨è¿‡æ»¤ NaN

      :param sec_thresh: number
          æ¬¡ç»´åº¦é˜ˆå€¼ï¼š
          - mode='rank' â†’ æ€»åˆ†åæ¬¡ä¸Šé™ï¼ˆåŒ…å«ï¼‰ï¼Œå¦‚ 100 â†’ åªç»Ÿè®¡æ€»åˆ†åæ¬¡ â‰¤100
          - mode='score' â†’ æ€»åˆ†åˆ†æ•°ä¸‹é™ï¼ˆåŒ…å«ï¼‰ï¼Œå¦‚ 450 â†’ åªç»Ÿè®¡æ€»åˆ†åˆ†æ•° â‰¥450

      :param mode: str, default='rank'
          'rank' â†’ åæ¬¡æ¨¡å¼ï¼šä¸»ç»´åº¦åŒºé—´ (lower, upper]ï¼Œæ¬¡ç»´åº¦æ¡ä»¶ â‰¤ sec_thresh
          'score' â†’ åˆ†æ•°æ¨¡å¼ï¼šä¸»ç»´åº¦åŒºé—´ [lower, upper)ï¼Œæ¬¡ç»´åº¦æ¡ä»¶ â‰¥ sec_thresh

    ğŸ¯ è¿”å›å€¼ï¼š
      :return: list of functions
          æ¯ä¸ªå‡½æ•°æ¥å— [(ä¸»ç»´åº¦å€¼, æ¬¡ç»´åº¦å€¼), ...] æ ¼å¼æ•°æ®ï¼Œè¿”å›æ»¡è¶³æ¡ä»¶çš„è®°å½•æ•°ã€‚
          å‘½åæ ¼å¼ï¼š
            - åæ¬¡æ¨¡å¼ï¼š'DC(0-60] Tâ‰¤100'
            - åˆ†æ•°æ¨¡å¼ï¼š'DC[80-90) Tâ‰¥450'
            - è¶…é™ç»Ÿè®¡ï¼š'DC(0-inf] T>100' æˆ– 'DC[0-inf) T<450'

    ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š

        # ===== åæ¬¡æ¨¡å¼ =====
        data_rank = [(10, 50), (70, 120), (90, 80), (110, 90)]
        counters = make_dual_cond_counters([0,60,80,100], 100, mode='rank')
        for c in counters:
            print(f"{c.__name__}: {c(data_rank)}")

        # ===== åˆ†æ•°æ¨¡å¼ =====
        data_score = [(85, 480), (75, 420), (92, 500), (65, 460)]
        counters = make_dual_cond_counters([60,70,80,90], 450, mode='score')
        for c in counters:
            print(f"{c.__name__}: {c(data_score)}")
    """
    # ========== å‚æ•°æ ¡éªŒ ==========
    # 1. éªŒè¯ thresh ç±»å‹
    if not isinstance(thresh, (list, tuple)):
        raise TypeError(f"'thresh' åº”ä¸º list æˆ– tupleï¼Œå½“å‰ç±»å‹: {type(thresh).__name__}")

    # 2. éªŒè¯ thresh é•¿åº¦
    if len(thresh) < 2:
        raise ValueError(f"'thresh' è‡³å°‘éœ€è¦2ä¸ªé˜ˆå€¼ï¼Œå½“å‰: {len(thresh)}")

    # 3. éªŒè¯ thresh å…ƒç´ ç±»å‹å’Œå€¼
    for i, x in enumerate(thresh):
        if not isinstance(x, (int, float)):
            raise TypeError(f"thresh ä¸­çš„å…ƒç´ å¿…é¡»ä¸ºæ•°å­—ï¼ˆint/floatï¼‰ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ {type(x).__name__}")
        if math.isnan(x):
            raise ValueError(f"thresh ä¸­çš„å…ƒç´ ä¸èƒ½ä¸º NaNï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ NaN")
        if x < 0:
            raise ValueError(f"thresh ä¸­çš„å…ƒç´ å¿…é¡»ä¸ºéè´Ÿæ•°ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ {x}")

    # 4. éªŒè¯ sec_thresh ç±»å‹å’Œå€¼
    if not isinstance(sec_thresh, (int, float)):
        raise TypeError(f"'sec_thresh' å¿…é¡»ä¸ºæ•°å­—ï¼ˆint/floatï¼‰ï¼Œå½“å‰ç±»å‹: {type(sec_thresh).__name__}")
    if math.isnan(sec_thresh):
        raise ValueError("'sec_thresh' ä¸èƒ½ä¸º NaN")
    if sec_thresh < 0:
        raise ValueError(f"'sec_thresh' å¿…é¡»ä¸ºéè´Ÿæ•°ï¼Œå½“å‰å€¼: {sec_thresh}")

    # 5. éªŒè¯ mode ç±»å‹å’Œå€¼
    if not isinstance(mode, str):
        raise TypeError(f"'mode' å¿…é¡»ä¸ºå­—ç¬¦ä¸²ï¼Œå½“å‰ç±»å‹: {type(mode).__name__}")
    if mode not in ('rank', 'score'):
        raise ValueError(f"mode å¿…é¡»ä¸º 'rank' æˆ– 'score'ï¼Œå½“å‰: {mode}")

    # 6. éªŒè¯ thresh æ˜¯å¦ä¸ºä¸¥æ ¼å‡åºåºåˆ—
    thresh_sorted = sorted(thresh)
    if thresh_sorted != list(thresh):
        print(f"âš ï¸  è­¦å‘Š: thresh å·²è‡ªåŠ¨æ’åºï¼ˆåŸ: {thresh} â†’ ç°: {thresh_sorted}ï¼‰")
    thresh = thresh_sorted

    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å€¼
    if len(set(thresh)) != len(thresh):
        raise ValueError("thresh ä¸­åŒ…å«é‡å¤å€¼")

    # ========== æ ¹æ® mode è®¾ç½®æ¯”è¾ƒé€»è¾‘ ==========
    if mode == 'rank':
        # åæ¬¡æ¨¡å¼ï¼šä¸»ç»´åº¦ (lower, upper]ï¼Œæ¬¡ç»´åº¦ <= sec_thresh
        main_lower_op = lambda x, l: x > l  # ä¸¥æ ¼å¤§äºä¸‹ç•Œ
        main_upper_op = lambda x, u: x <= u  # å°äºç­‰äºä¸Šç•Œ
        secondary_op = lambda y: y <= sec_thresh
        secondary_fail_op = lambda y: y > sec_thresh
        main_bracket = ('(', ']')
        secondary_prefix = 'Tâ‰¤'
        secondary_fail_prefix = 'T>'
    else:  # mode == 'score'
        # åˆ†æ•°æ¨¡å¼ï¼šä¸»ç»´åº¦ [lower, upper)ï¼Œæ¬¡ç»´åº¦ >= sec_thresh
        main_lower_op = lambda x, l: x >= l  # å¤§äºç­‰äºä¸‹ç•Œ
        main_upper_op = lambda x, u: x < u  # ä¸¥æ ¼å°äºä¸Šç•Œ
        secondary_op = lambda y: y >= sec_thresh
        secondary_fail_op = lambda y: y < sec_thresh
        main_bracket = ('[', ')')
        secondary_prefix = 'Tâ‰¥'
        secondary_fail_prefix = 'T<'

    # ========== ç”Ÿæˆè®¡æ•°å™¨ ==========
    def make_counter(lower, upper):
        def counter(arr):
            # æ–°å¢ï¼šå¤„ç† pandas Series
            if isinstance(arr, pd.Series):
                # è½¬æ¢ä¸ºåˆ—è¡¨
                arr = arr.tolist()

            # éªŒè¯è¾“å…¥æ•°æ®
            if not isinstance(arr, (list, tuple, np.ndarray)):
                raise TypeError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ– numpy æ•°ç»„")

            count = 0
            for item in arr:
                # éªŒè¯æ¯ä¸ªå…ƒç´ æ˜¯å¦ä¸ºå…ƒç»„ä¸”é•¿åº¦ä¸º2
                if not isinstance(item, (list, tuple)) or len(item) != 2:
                    raise ValueError("è¾“å…¥æ•°æ®çš„æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯é•¿åº¦ä¸º2çš„å…ƒç»„æˆ–åˆ—è¡¨")

                # éªŒè¯å…ƒç´ å€¼æ˜¯å¦ä¸ºæ•°å­—
                x, y = item
                if not (isinstance(x, (int, float)) and isinstance(y, (int, float))):
                    raise ValueError("è¾“å…¥æ•°æ®çš„æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯æ•°å­—")

                # æ£€æŸ¥æ¡ä»¶
                if main_lower_op(x, lower) and main_upper_op(x, upper) and secondary_op(y):
                    count += 1
            return count

        # æ ¼å¼åŒ–å‡½æ•°å
        if math.isinf(upper):
            counter.__name__ = f"DC{main_bracket[0]}{lower}-inf{main_bracket[1]} {secondary_prefix}{sec_thresh}"
        else:
            counter.__name__ = f"DC{main_bracket[0]}{lower}-{upper}{main_bracket[1]} {secondary_prefix}{sec_thresh}"
        return counter

    def last_counter(arr):
        # æ–°å¢ï¼šå¤„ç† pandas Series
        if isinstance(arr, pd.Series):
            # è½¬æ¢ä¸ºåˆ—è¡¨
            arr = arr.tolist()

        # éªŒè¯è¾“å…¥æ•°æ®
        if not isinstance(arr, (list, tuple, np.ndarray)):
            raise TypeError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ– numpy æ•°ç»„")

        count = 0
        for item in arr:
            # éªŒè¯æ¯ä¸ªå…ƒç´ æ˜¯å¦ä¸ºå…ƒç»„ä¸”é•¿åº¦ä¸º2
            if not isinstance(item, (list, tuple)) or len(item) != 2:
                raise ValueError("è¾“å…¥æ•°æ®çš„æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯é•¿åº¦ä¸º2çš„å…ƒç»„æˆ–åˆ—è¡¨")

            # éªŒè¯å…ƒç´ å€¼æ˜¯å¦ä¸ºæ•°å­—
            _, y = item
            if not isinstance(y, (int, float)):
                raise ValueError("è¾“å…¥æ•°æ®çš„æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯æ•°å­—")

            # æ£€æŸ¥æ¡ä»¶
            if secondary_fail_op(y):
                count += 1
        return count

    last_counter.__name__ = f"DC{main_bracket[0]}0-inf{main_bracket[1]} {secondary_fail_prefix}{sec_thresh}"

    # æ·»åŠ æ— ç©·å¤§ï¼Œç”ŸæˆåŒºé—´
    thresh_ext = thresh + [float('inf')]
    intervals = [(thresh_ext[i], thresh_ext[i + 1]) for i in range(len(thresh_ext) - 1)]

    # ç”Ÿæˆæ‰€æœ‰è®¡æ•°å™¨
    counters = [make_counter(l, u) for l, u in intervals] + [last_counter]
    return counters

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# æ ¹æ®é˜ˆå€¼ç”Ÿæˆä¸€ç»„æˆç»©åŒºé—´ç»Ÿè®¡å‡½æ•°ï¼ˆè®¡æ•° + æ¯”ç‡ï¼‰ï¼Œå¯é€‰ç”Ÿæˆä½äºæœ€ä½åˆ†ç»Ÿè®¡ã€å¹³å‡åˆ†å‡½æ•°å’Œæœ‰æ•ˆæ•°æ®ä¸ªæ•°ç»Ÿè®¡ã€‚
def make_rate_counters(
        thresh: Union[List[Union[int, float]], Tuple[Union[int, float], ...], np.ndarray],
        cumu: bool = True,
        include_mean: bool = True,
        include_below_min: bool = False,
        include_count_valid: int = 0
) -> Tuple[Callable, ...]:
    """
    æ ¹æ®é˜ˆå€¼ç”Ÿæˆä¸€ç»„æˆç»©åŒºé—´ç»Ÿè®¡å‡½æ•°ï¼ˆè®¡æ•° + æ¯”ç‡ï¼‰ï¼Œå¯é€‰ç”Ÿæˆä½äºæœ€ä½åˆ†ç»Ÿè®¡ã€å¹³å‡åˆ†å‡½æ•°å’Œæœ‰æ•ˆæ•°æ®ä¸ªæ•°ç»Ÿè®¡ã€‚
    2025.10.20,é˜¿é‡Œçµç ä¼˜åŒ–ã€‚
    ğŸ¯ æ ¸å¿ƒç‰¹æ€§ï¼š
      - ç›´æ¥è¿”å›å‡½æ•°ç»„ï¼Œæ— éœ€å­—å…¸åŒ…è£…ï¼›
      - å‡½æ•°åé‡‡ç”¨æ•°å­¦åŒºé—´é£æ ¼ï¼šcount[60,80)ã€ratio[60,80)ã€count[80,+âˆ)ã€ratio[80,+âˆ)ï¼›
      - æ”¯æŒåŒºé—´ç»Ÿè®¡å’Œç´¯è®¡ç»Ÿè®¡ä¸¤ç§æ¨¡å¼ï¼›
      - å¯é€‰ç”Ÿæˆä½äºæœ€ä½åˆ†çš„ç»Ÿè®¡å‡½æ•°ï¼ˆåœ¨ä¸¤ç§æ¨¡å¼ä¸‹å‡æœ‰æ•ˆï¼‰ï¼›
      - å¯é€‰ç”Ÿæˆå¹³å‡åˆ†è®¡ç®—å‡½æ•°ï¼ˆè‡ªåŠ¨å¿½ç•¥NaNå€¼ï¼‰ï¼›
      - æ–°å¢ï¼šå¯é€‰ç”Ÿæˆæœ‰æ•ˆæ•°æ®ä¸ªæ•°ç»Ÿè®¡å‡½æ•°ï¼ˆcount_validï¼‰ï¼Œä½ç½®ç”± include_count_valid æ§åˆ¶ã€‚

    ğŸ“Š ä½ç½®æ§åˆ¶é€»è¾‘ï¼š
      - include_count_valid = 0: ä¸æ·»åŠ  count_validï¼›
      - include_count_valid = 1: å°† count_valid æ·»åŠ åœ¨å‡½æ•°åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªä½ç½®ï¼›
      - include_count_valid = -1: å°† count_valid æ·»åŠ åœ¨å‡½æ•°åˆ—è¡¨çš„æœ€åä¸€ä¸ªä½ç½®ã€‚

    âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
      - å½“ cumu=True æ—¶ï¼ŒåŒºé—´è¡¨ç¤ºåˆ†æ•° >= é˜ˆå€¼çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚ ratio[80,+âˆ) è¡¨ç¤º 80 åˆ†åŠä»¥ä¸Šå æ¯”ã€‚
      - æ¯”ç‡è®¡ç®—æ—¶ï¼Œåˆ†æ¯ä¸ºè¾“å…¥æ•°ç»„çš„æ€»é•¿åº¦ï¼ˆåŒ…æ‹¬ NaN å€¼ï¼‰ã€‚è‹¥éœ€åŸºäºæœ‰æ•ˆæ•°æ®è®¡ç®—ï¼Œè¯·å…ˆè¿‡æ»¤ NaNã€‚

    :param thresh: list/tuple/ndarrayï¼Œé˜ˆå€¼åˆ—è¡¨ï¼Œå¿…é¡»æ˜¯é•¿åº¦ >=2 çš„å‡åºåºåˆ—ï¼›
    :param cumu: boolï¼Œæ˜¯å¦ä¸ºç´¯è®¡ç»Ÿè®¡æ¨¡å¼ã€‚True æ—¶ï¼Œæ¯ä¸ªé˜ˆå€¼ t ç”Ÿæˆ [t, +âˆ) åŒºé—´ç»Ÿè®¡ï¼ˆå³ >=tï¼‰ã€‚
    :param include_mean: bool, æ˜¯å¦ç”Ÿæˆè®¡ç®—å¹³å‡åˆ†çš„å‡½æ•°ï¼Œé»˜è®¤ Trueï¼›
    :param include_below_min: bool, æ˜¯å¦ç”Ÿæˆä½äºæœ€ä½åˆ†çš„ç»Ÿè®¡å‡½æ•°ï¼Œé»˜è®¤ Falseï¼›
    :param include_count_valid: int, æ§åˆ¶ count_valid çš„ä½ç½®ï¼ˆ0=ä¸æ·»åŠ , 1=ç¬¬ä¸€ä¸ªä½ç½®, -1=æœ€åä¸€ä¸ªä½ç½®ï¼‰ï¼›
    :return: tupleï¼ŒåŒ…å«æ‰€æœ‰ç”Ÿæˆçš„ç»Ÿè®¡å‡½æ•°ã€‚

    :raises ValueError: å½“å‚æ•°ä¸ç¬¦åˆè¦æ±‚æ—¶ï¼›
    :raises TypeError: å½“å‚æ•°ç±»å‹ä¸æ­£ç¡®æ—¶ã€‚
    """
    # å‚æ•°éªŒè¯ã€‚
    if not isinstance(thresh, (list, tuple, np.ndarray)):
        raise TypeError("thresh å¿…é¡»ä¸ºåˆ—è¡¨ã€å…ƒç»„æˆ– numpy æ•°ç»„ã€‚")

    if isinstance(thresh, np.ndarray):
        thresh = thresh.tolist()

    if len(thresh) < 2:
        raise ValueError("thresh å¿…é¡»åŒ…å«è‡³å°‘ 2 ä¸ªå…ƒç´ ã€‚")

    for i, t in enumerate(thresh):
        if not isinstance(t, (int, float)):
            raise TypeError(f"thresh ä¸­çš„æ‰€æœ‰å…ƒç´ å¿…é¡»æ˜¯æ•°å­—ç±»å‹ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ æ˜¯ {type(t)}ã€‚")

    for i in range(len(thresh) - 1):
        if thresh[i] >= thresh[i + 1]:
            raise ValueError("thresh å¿…é¡»æ˜¯ä¸¥æ ¼å‡åºåºåˆ—ã€‚")

    if not isinstance(cumu, bool):
        raise TypeError("cumu å¿…é¡»æ˜¯å¸ƒå°”å€¼ã€‚")

    if not isinstance(include_below_min, bool):
        raise TypeError("include_below_min å¿…é¡»æ˜¯å¸ƒå°”å€¼ã€‚")

    if not isinstance(include_mean, bool):
        raise TypeError("include_mean å¿…é¡»æ˜¯å¸ƒå°”å€¼ã€‚")

    if not isinstance(include_count_valid, int):
        raise TypeError("include_count_valid å¿…é¡»æ˜¯æ•´æ•°ï¼ˆ0, 1, -1ï¼‰ã€‚")

    if include_count_valid not in [0, 1, -1]:
        raise ValueError("include_count_valid å¿…é¡»æ˜¯ 0, 1 æˆ– -1ã€‚")

    for i, t in enumerate(thresh):
        if t < 0:
            raise ValueError(f"thresh ä¸­çš„æ‰€æœ‰å…ƒç´ å¿…é¡»ä¸ºéè´Ÿæ•°ï¼Œä½†ç´¢å¼• {i} çš„å…ƒç´ ä¸º {t}ã€‚")

    def make_threshold_func(lower, upper=None, ratio=False, cumu_mode=False, is_last_interval=False, below_min=False):
        """
        å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼Œç”¨äºåˆ›å»ºé˜ˆå€¼ç›¸å…³çš„ç»Ÿè®¡å‡½æ•°ï¼ˆè®¡æ•°/æ¯”ç‡ï¼‰ã€‚
        """

        def func(scores):
            # å¤„ç† pandas Series å¯¹è±¡ã€‚
            if isinstance(scores, pd.Series):
                if scores.empty:
                    return np.nan if ratio else 0
                arr = scores.values
            elif not isinstance(scores, (list, tuple, np.ndarray)):
                raise TypeError("è¾“å…¥åˆ†æ•°å¿…é¡»æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ– numpy æ•°ç»„ã€‚")
            else:
                arr = np.array(scores)

            # å°è¯•å°†æ•°ç»„è½¬æ¢ä¸º floatï¼Œä»¥å¤„ç†æ··åˆç±»å‹æˆ– NaN
            try:
                arr = arr.astype(float)
            except (ValueError, TypeError):
                raise TypeError("åˆ†æ•°æ•°ç»„å¿…é¡»èƒ½è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚")

            mask = np.zeros(arr.shape, dtype=bool)  # åˆå§‹åŒ–æ©ç ã€‚

            if below_min:
                mask = arr < lower
            elif cumu_mode:
                # åœ¨ cumu æ¨¡å¼ä¸‹ï¼Œis_last_interval å‚æ•°ä¸å†ä¼ å…¥ï¼Œé€»è¾‘ç®€åŒ–
                mask = arr >= lower
            else:
                if is_last_interval:
                    mask = (arr >= lower) & (arr <= upper)
                else:
                    mask = (arr >= lower) & (arr < upper)

            count = np.sum(mask)
            total = len(arr)
            return count / total if ratio and total > 0 else int(count)

        # ç”Ÿæˆå‡½æ•°åã€‚
        prefix = "ratio" if ratio else "count"
        if below_min:
            func_name = f"{prefix}(-âˆ,{lower})"
        elif cumu_mode:
            func_name = f"{prefix}[{lower},+âˆ)"
        else:
            if is_last_interval:
                func_name = f"{prefix}[{lower},{upper}]"
            else:
                func_name = f"{prefix}[{lower},{upper})"
        func.__name__ = func_name
        return func

    def make_mean_func():
        """
        å¹³å‡åˆ†è®¡ç®—å‡½æ•°ï¼šè‡ªåŠ¨å¿½ç•¥ NaN å€¼ã€‚
        """

        def func(scores):
            if isinstance(scores, pd.Series):
                arr = scores.values
            elif not isinstance(scores, (list, tuple, np.ndarray)):
                raise TypeError("è¾“å…¥åˆ†æ•°å¿…é¡»æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ– numpy æ•°ç»„ã€‚")
            else:
                arr = np.array(scores)

            # å°è¯•å°†æ•°ç»„è½¬æ¢ä¸º float
            try:
                arr = arr.astype(float)
            except (ValueError, TypeError):
                raise TypeError("åˆ†æ•°æ•°ç»„å¿…é¡»èƒ½è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚")

            # è¿‡æ»¤æ‰ NaN å€¼ã€‚
            valid = arr[~np.isnan(arr)]

            if len(valid) == 0:
                return np.nan

            return float(np.mean(valid))

        func.__name__ = "mean"
        return func

    def make_count_valid_func():
        """
        æœ‰æ•ˆæ•°æ®ä¸ªæ•°ç»Ÿè®¡å‡½æ•°ã€‚
        """

        def func(scores):
            if isinstance(scores, pd.Series):
                arr = scores.values
            elif not isinstance(scores, (list, tuple, np.ndarray)):
                raise TypeError("è¾“å…¥åˆ†æ•°å¿…é¡»æ˜¯åˆ—è¡¨ã€å…ƒç»„æˆ– numpy æ•°ç»„ã€‚")
            else:
                arr = np.array(scores)

            # å°è¯•å°†æ•°ç»„è½¬æ¢ä¸º float
            try:
                arr = arr.astype(float)
            except (ValueError, TypeError):
                raise TypeError("åˆ†æ•°æ•°ç»„å¿…é¡»èƒ½è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚")

            # è®¡ç®—æœ‰æ•ˆæ•°æ®ä¸ªæ•°ï¼ˆé NaNï¼‰ã€‚
            valid = ~np.isnan(arr)
            return int(np.sum(valid))

        func.__name__ = "count_valid"
        return func

    funcs = []
    n = len(thresh)
    min_thresh = thresh[0]

    # ç”Ÿæˆä½äºæœ€ä½åˆ†çš„ç»Ÿè®¡ã€‚
    if include_below_min:
        below_count_func = make_threshold_func(min_thresh, ratio=False, below_min=True)
        below_ratio_func = make_threshold_func(min_thresh, ratio=True, below_min=True)
        funcs.extend([below_count_func, below_ratio_func])

    # ç”Ÿæˆé˜ˆå€¼åŒºé—´ç»Ÿè®¡ã€‚
    for i in range(n - 1):
        lower = thresh[i]
        upper = thresh[i + 1]
        is_last_interval = (i == n - 2)

        # æ ¹æ® cumu æ¨¡å¼é€‰æ‹©è°ƒç”¨æ–¹å¼ï¼Œé¿å…ä¼ é€’æ— ç”¨å‚æ•°
        if cumu:
            count_func = make_threshold_func(lower, ratio=False, cumu_mode=True)
            ratio_func = make_threshold_func(lower, ratio=True, cumu_mode=True)
        else:
            count_func = make_threshold_func(lower, upper, ratio=False, is_last_interval=is_last_interval)
            ratio_func = make_threshold_func(lower, upper, ratio=True, is_last_interval=is_last_interval)

        funcs.extend([count_func, ratio_func])

    # ç”Ÿæˆå¹³å‡åˆ†ç»Ÿè®¡ã€‚
    if include_mean:
        mean_func = make_mean_func()
        funcs.append(mean_func)

    # æ ¹æ® include_count_valid æ·»åŠ æœ‰æ•ˆæ•°æ®ä¸ªæ•°ç»Ÿè®¡ã€‚
    if include_count_valid != 0:
        count_valid_func = make_count_valid_func()
        if include_count_valid == 1:
            funcs.insert(0, count_valid_func)  # æ’å…¥åˆ°ç¬¬ä¸€ä¸ªä½ç½®ã€‚
        elif include_count_valid == -1:
            funcs.append(count_valid_func)  # æ’å…¥åˆ°æœ€åä¸€ä¸ªä½ç½®ã€‚

    return tuple(funcs)


# --- ç¤ºä¾‹ç”¨æ³• ---
if __name__ == "__main__":
    # å®šä¹‰é˜ˆå€¼
    thresholds = [60, 70, 80, 90]
    print(f"é˜ˆå€¼: {thresholds}")
    print(f"ç´¯è®¡æ¨¡å¼ (cumu=True):")

    # ç”Ÿæˆç»Ÿè®¡å‡½æ•°ç»„
    stat_funcs = make_rate_counters(thresholds, cumu=True, include_mean=True, include_below_min=True,
                                    include_count_valid=-1)

    # ç¤ºä¾‹æ•°æ®
    sample_scores = [55, 65, 75, 85, 95, 88, 72, 60, 90, np.nan]
    print(f"ç¤ºä¾‹æ•°æ®: {sample_scores}")

    # æ‰“å°æ‰€æœ‰ç”Ÿæˆçš„å‡½æ•°åç§°
    print("\nç”Ÿæˆçš„å‡½æ•°åˆ—è¡¨:")
    for i, func in enumerate(stat_funcs):
        print(f"  [{i:2d}] {func.__name__}")

    print("\nè®¡ç®—ç¤ºä¾‹æ•°æ®çš„ç»Ÿè®¡ç»“æœ:")
    for func in stat_funcs:
        result = func(sample_scores)
        print(f"  {func.__name__}: {result:.4f}" if isinstance(result, float) else f"  {func.__name__}: {result}")

    print("\n" + "=" * 50)
    print(f"éç´¯è®¡æ¨¡å¼ (cumu=False):")
    stat_funcs2 = make_rate_counters(thresholds, cumu=False, include_mean=True, include_below_min=True,
                                     include_count_valid=-1)

    print("\nç”Ÿæˆçš„å‡½æ•°åˆ—è¡¨:")
    for i, func in enumerate(stat_funcs2):
        print(f"  [{i:2d}] {func.__name__}")

    print("\nè®¡ç®—ç¤ºä¾‹æ•°æ®çš„ç»Ÿè®¡ç»“æœ:")
    for func in stat_funcs2:
        result = func(sample_scores)
        print(f"  {func.__name__}: {result:.4f}" if isinstance(result, float) else f"  {func.__name__}: {result}")


# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 


# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–    dfæ•°æ®ä¸å·¥ä½œè¡¨å•å…ƒ  â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# è¿”å›å·¥ä½œè–„ä¸æŒ‡å®šå·¥ä½œè¡¨ã€‚
def trim_wb(
        wb: Workbook,
        sheet_names: Union[str, List[str]]
        ) -> Tuple[Workbook, Union[Worksheet, List[Worksheet]]]:
    """
    åªä¿ç•™æŒ‡å®šåç§°çš„å·¥ä½œè¡¨ï¼Œå¹¶åˆ é™¤å·¥ä½œç°¿ä¸­çš„å…¶ä»–æ‰€æœ‰å·¥ä½œè¡¨ã€‚

    :param wb: openpyxlå·¥ä½œç°¿å¯¹è±¡
    :param sheet_names: è¦ä¿ç•™çš„å·¥ä½œè¡¨åç§°ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
    :return: å…ƒç»„åŒ…å«ï¼ˆä¿®æ”¹åçš„å·¥ä½œç°¿å¯¹è±¡, ä¿ç•™çš„å·¥ä½œè¡¨å¯¹è±¡/åˆ—è¡¨ï¼‰
    :raises ValueError: å¦‚æœæŒ‡å®šçš„å·¥ä½œè¡¨åç§°ä¸å­˜åœ¨äºå·¥ä½œç°¿ä¸­
    """
    # ç»Ÿä¸€è¾“å…¥æ ¼å¼ä¸ºåˆ—è¡¨
    if isinstance(sheet_names, str):
        sheet_names = [sheet_names]

    # æ£€æŸ¥æ‰€æœ‰æŒ‡å®šçš„å·¥ä½œè¡¨æ˜¯å¦å­˜åœ¨
    missing_sheets = [name for name in sheet_names if name not in wb.sheetnames]
    if missing_sheets:
        raise ValueError(f"å·¥ä½œè¡¨ {missing_sheets} ä¸å­˜åœ¨äºå·¥ä½œç°¿ä¸­")

    # åˆ é™¤ä¸åœ¨ä¿ç•™åˆ—è¡¨ä¸­çš„å·¥ä½œè¡¨
    sheets_to_remove = [sheet for sheet in wb.worksheets if sheet.title not in sheet_names]
    for sheet in sheets_to_remove:
        wb.remove(sheet)

    # è¿”å›å·¥ä½œç°¿å’Œä¿ç•™çš„å·¥ä½œè¡¨å¯¹è±¡
    retained_sheets = [wb[name] for name in sheet_names]

    # å¦‚æœåªä¿ç•™ä¸€ä¸ªå·¥ä½œè¡¨ï¼Œè¿”å›å•ä¸ªå·¥ä½œè¡¨å¯¹è±¡ï¼›å¦åˆ™è¿”å›åˆ—è¡¨
    if len(sheet_names) == 1:
        return wb, retained_sheets[0]
    else:
        return wb, retained_sheets

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# å°†ä¸€ä¸ªæˆ–å¤šä¸ªPandas DataFrameé€ä¸€æ³¨å…¥åˆ°ä¸€ä¸ªç”±openpyxlåˆ›å»ºçš„å·¥ä½œè¡¨ä¸­ã€‚
def dfs_to_ws(
        ws: Any,
        row: int,
        col: int,
        dfs: Union[pd.DataFrame, List[pd.DataFrame]],
        rg: int = 10,
        cg: int = 0,
        hd: bool = False,
        idx: bool = False,
        na_rep: Optional[Any] = None
        ) -> None:
    """
    å°†ä¸€ä¸ªæˆ–å¤šä¸ªPandas DataFrameé€ä¸€æ³¨å…¥åˆ°ä¸€ä¸ªç”±openpyxlåˆ›å»ºçš„å·¥ä½œè¡¨ä¸­ã€‚
    ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼šæ•°æ®å†™å…¥å’Œå¸ƒå±€æ§åˆ¶ã€‚

    å‚æ•°:
    ----------
    ws : openpyxl.worksheet.worksheet.Worksheet
        ç”±openpyxlåˆ›å»ºçš„å·¥ä½œè¡¨å¯¹è±¡ï¼Œæ•°æ®å°†è¢«å†™å…¥æ­¤å·¥ä½œè¡¨

    row : int
        ç¬¬ä¸€ä¸ªDataFrameçš„èµ·å§‹è¡Œåæ ‡ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰

    col : int
        ç¬¬ä¸€ä¸ªDataFrameçš„èµ·å§‹åˆ—åæ ‡ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰

    dfs : pandas.DataFrame æˆ– list of pandas.DataFrame
        è¦å†™å…¥çš„ä¸€ä¸ªæˆ–å¤šä¸ªDataFrameå¯¹è±¡ã€‚å¯ä»¥æ˜¯å•ä¸ªDataFrameæˆ–DataFrameåˆ—è¡¨

    rg : int, å¯é€‰, é»˜è®¤å€¼: 10
        DataFrameä¹‹é—´çš„è¡Œé—´è·ï¼ˆè¡Œé—´éš”æ•°ï¼‰ã€‚æ§åˆ¶ä¸€ä¸ªDataFrameç»“æŸååˆ°ä¸‹ä¸€ä¸ª
        DataFrameå¼€å§‹å‰çš„ç©ºè¡Œæ•°é‡

    cg : int, å¯é€‰, é»˜è®¤å€¼: 0
        DataFrameä¹‹é—´çš„åˆ—é—´è·ï¼ˆåˆ—é—´éš”æ•°ï¼‰ã€‚æ§åˆ¶ä¸€ä¸ªDataFrameç»“æŸååˆ°ä¸‹ä¸€ä¸ª
        DataFrameå¼€å§‹å‰çš„ç©ºåˆ—æ•°é‡

    hd : bool, å¯é€‰, é»˜è®¤å€¼: False
        æ˜¯å¦åŒ…å«DataFrameçš„åˆ—å¤´ï¼ˆè¡¨å¤´ï¼‰ã€‚å¦‚æœä¸ºTrueï¼Œåˆ™å°†DataFrameçš„åˆ—å
        ä½œä¸ºç¬¬ä¸€è¡Œå†™å…¥

    idx : bool, å¯é€‰, é»˜è®¤å€¼: False
        æ˜¯å¦åŒ…å«DataFrameçš„ç´¢å¼•ã€‚å¦‚æœä¸ºTrueï¼Œåˆ™å°†ç´¢å¼•ä½œä¸ºç¬¬ä¸€åˆ—å†™å…¥

    na_rep : ä»»æ„ç±»å‹, å¯é€‰, é»˜è®¤å€¼: None
        NaNå€¼çš„æ›¿ä»£è¡¨ç¤ºã€‚å½“DataFrameä¸­åŒ…å«NaNã€NaTç­‰ç©ºå€¼æ—¶ï¼Œä½¿ç”¨æ­¤å€¼è¿›è¡Œæ›¿æ¢ã€‚
        å¦‚æœä¿æŒä¸ºNoneï¼Œåˆ™ç©ºå€¼å°†ä¿æŒä¸ºNoneï¼ˆåœ¨Excelä¸­æ˜¾ç¤ºä¸ºç©ºå•å…ƒæ ¼ï¼‰

    è¿”å›:
    -------
    None
        æ­¤å‡½æ•°ä¸è¿”å›ä»»ä½•å€¼ï¼Œç›´æ¥ä¿®æ”¹ä¼ å…¥çš„å·¥ä½œè¡¨å¯¹è±¡

    å¼‚å¸¸:
    ------
    ValueError
        å¦‚æœwså‚æ•°ä¸æ˜¯æœ‰æ•ˆçš„Worksheetå¯¹è±¡ï¼Œæˆ–è€…dfså‚æ•°ä¸æ˜¯DataFrameæˆ–DataFrameåˆ—è¡¨

    æ³¨æ„äº‹é¡¹:
    ---------
    1. æ­¤å‡½æ•°ä¼šç›´æ¥ä¿®æ”¹ä¼ å…¥çš„å·¥ä½œè¡¨å¯¹è±¡ï¼Œä½†ä¸ä¼šè‡ªåŠ¨ä¿å­˜å·¥ä½œç°¿
    2. ç©ºå€¼å¤„ç†ä½¿ç”¨Pandasçš„isnull()æ–¹æ³•ï¼Œå¯ä»¥è¯†åˆ«å¤šç§ç©ºå€¼ç±»å‹ï¼ˆNaNã€NaTç­‰ï¼‰
    3. å¯¹äºå¤§å‹DataFrameï¼Œå»ºè®®ä½¿ç”¨na_repå‚æ•°å¤„ç†ç©ºå€¼ï¼Œé¿å…Excelæ˜¾ç¤ºé”™è¯¯
    4. å‡½æ•°é‡‡ç”¨æ‰¹é‡å†™å…¥æ–¹å¼ä¼˜åŒ–æ€§èƒ½ï¼Œå‡å°‘æ–¹æ³•è°ƒç”¨æ¬¡æ•°
    """
    # æ£€æŸ¥wsæ˜¯å¦ä¸ºWorksheetå¯¹è±¡
    if not hasattr(ws, 'cell'):
        raise ValueError("wså¿…é¡»æ˜¯ä¸€ä¸ªopenpyxlçš„Worksheetå¯¹è±¡")

    # å°†å•ä¸ªDataFrameè½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(dfs, pd.DataFrame):
        dfs = [dfs]

    # æ£€æŸ¥dfsæ˜¯å¦ä¸ºDataFrameåˆ—è¡¨
    if not all(isinstance(df, pd.DataFrame) for df in dfs):
        raise ValueError("dfså¿…é¡»æ˜¯ä¸€ä¸ªPandas DataFrameå¯¹è±¡æˆ–åŒ…å«Pandas DataFrameå¯¹è±¡çš„åˆ—è¡¨")

    # æ£€æŸ¥è¡Œåˆ—å‚æ•°çš„æœ‰æ•ˆæ€§
    if row < 1 or col < 1:
        raise ValueError("è¡Œå’Œåˆ—å‚æ•°å¿…é¡»å¤§äºç­‰äº1")

    # éå†æ¯ä¸ªDataFrame
    for df_idx, df in enumerate(dfs):
        # æ£€æŸ¥DataFrameæ˜¯å¦ä¸ºç©º
        if df.empty:
            warnings.warn(f"ç¬¬{df_idx + 1}ä¸ªDataFrameä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
            continue

        # è·å–æ‰€æœ‰è¡Œæ•°æ®ï¼ˆæå‰è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œé¿å…é‡å¤ç”Ÿæˆï¼‰
        try:
            rows = list(dataframe_to_rows(df, index=idx, header=hd))
        except Exception as e:
            raise ValueError(f"å¤„ç†ç¬¬{df_idx + 1}ä¸ªDataFrameæ—¶å‡ºé”™: {str(e)}")

        # æ‰¹é‡å†™å…¥æ•°æ®
        for r_offset, row_data in enumerate(rows):
            for c_offset, value in enumerate(row_data):
                # å¤„ç†NaNå€¼
                if pd.isnull(value):
                    value = na_rep
                # å¤„ç†å…ƒç»„ç±»å‹çš„å€¼ï¼ˆå¦‚å¤šçº§åˆ—ç´¢å¼•åç§°ï¼‰
                elif isinstance(value, tuple):
                    # å°†å…ƒç»„è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼
                    value = '_'.join(str(v) for v in value)

                # è®¡ç®—å®é™…å•å…ƒæ ¼ä½ç½®
                current_row = row + r_offset
                current_col = col + c_offset

                # æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦ä¸ºåˆå¹¶å•å…ƒæ ¼ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™æ‰¾åˆ°åˆå¹¶åŒºåŸŸçš„èµ·å§‹å•å…ƒæ ¼
                cell = ws.cell(row=current_row, column=current_col)
                if hasattr(cell, 'merged_cell') and cell.merged_cell:
                    # å¯¹äºåˆå¹¶å•å…ƒæ ¼ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°å·¦ä¸Šè§’çš„å•å…ƒæ ¼æ¥å†™å…¥å€¼
                    for merged_range in ws.merged_cells.ranges:
                        if cell.coordinate in merged_range:
                            # è·å–åˆå¹¶åŒºåŸŸçš„èµ·å§‹å•å…ƒæ ¼
                            cell = ws.cell(row=merged_range.min_row, column=merged_range.min_col)
                            break
                
                # ç›´æ¥èµ‹å€¼
                cell.value = value

        # æ›´æ–°ä½ç½®ä¸ºä¸‹ä¸€ä¸ªDataFrameçš„èµ·å§‹ä½ç½®
        row +=  rg
        col +=  cg

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦ä¸º pandas DataFrameï¼Œå¹¶éªŒè¯ä»¥ä¸‹æ¡ä»¶
def validate_dataframe(
    data,
    required_columns: list,
    allow_extra_columns: bool = True
    ) -> pd.DataFrame:
    """
    æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦ä¸º pandas DataFrameï¼Œå¹¶éªŒè¯æ•°æ®ç»“æ„ä¸å†…å®¹è´¨é‡ã€‚

    æ£€æŸ¥é¡¹åŒ…æ‹¬ï¼š
    1. æ˜¯å¦ä¸º DataFrameï¼›
    2. æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€åˆ—ï¼›
    3. ï¼ˆå¯é€‰ï¼‰æ˜¯å¦åŒ…å«é¢å¤–åˆ—ï¼›
    4. å“ªäº›åˆ—å­˜åœ¨ç©ºå€¼ï¼ˆNaN/Noneï¼‰ï¼›
    5. å“ªäº›æ•°å€¼åˆ—å­˜åœ¨ 0 å€¼ã€‚

    è¿”å›ä¸€ä¸ªåŒ…å«ä¸­æ–‡æ£€æŸ¥é¡¹ã€é€šè¿‡çŠ¶æ€å’Œè¯¦ç»†è¯´æ˜çš„åé¦ˆè¡¨æ ¼ã€‚
    """
    results = []

    # 1. æ˜¯å¦ä¸º DataFrame
    is_dataframe = isinstance(data, pd.DataFrame)
    results.append({
        "æ£€æŸ¥é¡¹": "æ•°æ®ç±»å‹",
        "æ˜¯å¦é€šè¿‡": is_dataframe,
        "è¯´æ˜": "è¾“å…¥æ˜¯ pandas DataFrame" if is_dataframe else "è¾“å…¥ä¸æ˜¯ pandas DataFrame"
    })

    if not is_dataframe:
        return pd.DataFrame(results)

    df = data
    if df.empty:
        results.append({
            "æ£€æŸ¥é¡¹": "æ•°æ®æ˜¯å¦ä¸ºç©º",
            "æ˜¯å¦é€šè¿‡": False,
            "è¯´æ˜": "DataFrame ä¸ºç©ºï¼ˆæ— è¡Œæˆ–æ— åˆ—ï¼‰"
        })
        return pd.DataFrame(results)

    actual_columns = set(df.columns)
    required_set = set(required_columns)

    # 2. æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€åˆ—
    missing_required = sorted(required_set - actual_columns)
    has_all_required = len(missing_required) == 0
    msg_req = "åŒ…å«æ‰€æœ‰å¿…éœ€åˆ—" if has_all_required else f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_required}"
    results.append({
        "æ£€æŸ¥é¡¹": "å¿…éœ€åˆ—æ ‡",
        "æ˜¯å¦é€šè¿‡": has_all_required,
        "è¯´æ˜": msg_req
    })

    # 3. æ˜¯å¦æœ‰é¢å¤–åˆ—ï¼ˆä»…å½“ä¸å…è®¸é¢å¤–åˆ—æ—¶æ£€æŸ¥ï¼‰
    if not allow_extra_columns:
        extra_cols = sorted(actual_columns - required_set)
        no_extra = len(extra_cols) == 0
        msg_extra = "æ— é¢å¤–åˆ—ï¼ˆåˆ—ç»“æ„ä¸¥æ ¼åŒ¹é…ï¼‰" if no_extra else f"å­˜åœ¨é¢å¤–åˆ—: {extra_cols}"
        results.append({
            "æ£€æŸ¥é¡¹": "é¢å¤–åˆ—æ ‡",
            "æ˜¯å¦é€šè¿‡": no_extra,
            "è¯´æ˜": msg_extra
        })

    # 4. æ£€æŸ¥ç©ºå€¼ï¼ˆNaN/Noneï¼‰â€”â€”åˆ—å‡ºå…·ä½“åˆ—
    nan_series = df.isnull().any()
    nan_cols = sorted(nan_series[nan_series].index.tolist())
    has_nan = len(nan_cols) > 0
    msg_nan = "æ— ç©ºå€¼" if not has_nan else f"ä»¥ä¸‹åˆ—åŒ…å«ç©ºå€¼: {nan_cols}"
    results.append({
        "æ£€æŸ¥é¡¹": "æ£€æŸ¥ç©ºå€¼",
        "æ˜¯å¦é€šè¿‡": not has_nan,
        "è¯´æ˜": msg_nan
    })

    # 5. æ£€æŸ¥ 0 å€¼ï¼ˆä»…æ•°å€¼åˆ—ï¼‰â€”â€”åˆ—å‡ºå…·ä½“åˆ—
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    zero_cols = []
    if len(numeric_cols) > 0:
        zero_mask = (df[numeric_cols] == 0)
        zero_cols = sorted(zero_mask.any()[zero_mask.any()].index.tolist())
    has_zero = len(zero_cols) > 0
    msg_zero = "æ— æ•°å€¼åˆ—ä¸­çš„ 0 å€¼" if not has_zero else f"ä»¥ä¸‹åˆ—åŒ…å«0å€¼: {zero_cols}"
    results.append({
        "æ£€æŸ¥é¡¹": "æ£€æŸ¥0å€¼",
        "æ˜¯å¦é€šè¿‡": not has_zero,
        "è¯´æ˜": msg_zero
    })

    return pd.DataFrame(results)

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# ================================dfæ•°æ®æ“ä½œå•å…ƒ=====================================================
# å°†å…·æœ‰å¤šçº§åˆ—ç´¢å¼•çš„DataFrameæŒ‰ç…§æŒ‡å®šå±‚çº§æ‹†åˆ†æˆå¤šä¸ªDataFrameã€‚
def df_split_levels(
        df: pd.DataFrame,
        level: int = 0,
        keep_level: Union[int, bool] = 0
        ) -> Dict[Any, pd.DataFrame]:
    """
    å°†å…·æœ‰å¤šçº§åˆ—ç´¢å¼•çš„DataFrameæŒ‰ç…§æŒ‡å®šå±‚çº§æ‹†åˆ†æˆå¤šä¸ªDataFrameã€‚

    å‚æ•°:
        df: è¾“å…¥çš„DataFrameï¼Œåº”è¯¥å…·æœ‰å¤šçº§åˆ—ç´¢å¼•
        level: æ‹†åˆ†DataFrameçš„å±‚çº§ï¼Œé»˜è®¤ä¸º0ï¼ˆç¬¬ä¸€çº§ï¼‰
        keep_level:
            - 0: åˆ é™¤æ‹†åˆ†æ‰€ç”¨çš„å±‚çº§ï¼ˆé»˜è®¤ï¼‰
            - 1: ä¿ç•™æ‰€æœ‰å±‚çº§
            - -1: å°†å½“å‰å±‚çº§çš„ç´¢å¼•å€¼æ·»åŠ åˆ°ä¸‹ä¸€çº§ç´¢å¼•å€¼ä¸­ï¼Œç„¶ååˆ é™¤å½“å‰å±‚çº§

    è¿”å›:
        å­—å…¸{å±‚çº§å€¼: DataFrame}ï¼Œå…¶ä¸­é”®æ˜¯æ‹†åˆ†å±‚çº§çš„å”¯ä¸€å€¼

    å¼‚å¸¸:
        ValueError: å¦‚æœè¾“å…¥çš„DataFrameæ²¡æœ‰å¤šçº§åˆ—ç´¢å¼•æˆ–æŒ‡å®šçš„å±‚çº§æ— æ•ˆ
    """
    # ç¡®ä¿DataFrameå…·æœ‰å¤šçº§åˆ—ç´¢å¼•
    if not isinstance(df.columns, pd.MultiIndex):
        raise ValueError("è¾“å…¥çš„DataFrameå¿…é¡»å…·æœ‰å¤šçº§åˆ—ç´¢å¼•")

    # éªŒè¯æŒ‡å®šçš„å±‚çº§æ˜¯å¦æœ‰æ•ˆ
    nlevels = df.columns.nlevels
    if not (-nlevels <= level < nlevels):
        raise ValueError(f"å±‚çº§ {level} è¶…å‡ºäº†DataFrameçš„åˆ—ç´¢å¼•èŒƒå›´ (-{nlevels} åˆ° {nlevels - 1})")

    # éªŒè¯keey_levelå‚æ•°
    if keep_level not in [0, 1, -1]:
        raise ValueError("keey_levelå‚æ•°å¿…é¡»æ˜¯0ã€1æˆ–-1")

    # å¤„ç†è´Ÿç´¢å¼•
    level = level % nlevels

    # è·å–æŒ‡å®šå±‚çº§çš„æ‰€æœ‰å”¯ä¸€æ ‡ç­¾
    level_values = df.columns.get_level_values(level)
    unique_labels = level_values.unique()

    # å­˜å‚¨ç»“æœ
    result = {}

    # éå†æ¯ä¸ªå”¯ä¸€æ ‡ç­¾
    for label in unique_labels:
        # é€‰æ‹©æ‰€æœ‰åœ¨æŒ‡å®šå±‚çº§å…·æœ‰è¯¥æ ‡ç­¾çš„åˆ—
        mask = level_values == label
        temp_df = df.loc[:, mask].copy()

        # å¤„ç†åˆ—ç´¢å¼•
        if keep_level == 0:
            # åˆ é™¤æ‹†åˆ†æ‰€ç”¨çš„å±‚çº§
            if temp_df.columns.nlevels > 1:
                temp_df.columns = temp_df.columns.droplevel(level)

        elif keep_level == -1:
            # å°†å½“å‰å±‚çº§çš„ç´¢å¼•å€¼æ·»åŠ åˆ°ä¸‹ä¸€çº§ç´¢å¼•å€¼ä¸­
            if temp_df.columns.nlevels > 1:
                # æ„å»ºæ–°çš„åˆ—å
                new_columns = []
                for col in temp_df.columns:
                    # å°†å…ƒç»„è½¬æ¢ä¸ºåˆ—è¡¨
                    col_list = list(col)

                    # æ„å»ºæ–°çš„åˆ—å
                    if level + 1 < len(col_list):
                        # åˆå¹¶å½“å‰å±‚çº§å’Œä¸‹ä¸€å±‚çº§çš„å€¼
                        merged_value = f"{col_list[level]}_{col_list[level + 1]}"
                        # åˆ é™¤å½“å‰å±‚çº§å’Œä¸‹ä¸€å±‚çº§
                        del col_list[level:level + 2]
                        # æ’å…¥åˆå¹¶åçš„å€¼
                        col_list.insert(level, merged_value)
                    else:
                        # åªæœ‰å½“å‰å±‚çº§çš„æƒ…å†µ
                        merged_value = str(col_list[level])
                        # åˆ é™¤å½“å‰å±‚çº§
                        del col_list[level]
                        col_list.append(merged_value)

                    # å¦‚æœåªå‰©ä¸‹ä¸€ä¸ªå±‚çº§ï¼Œåˆ™ç›´æ¥ä½¿ç”¨è¯¥å€¼
                    new_columns.append(col_list[0] if len(col_list) == 1 else tuple(col_list))

                temp_df.columns = new_columns

        # æ— è®ºkeey_levelä¸ºä½•å€¼ï¼Œéƒ½ä¸æ˜¾ç¤ºåˆ—ç´¢å¼•åç§°
        if isinstance(temp_df.columns, pd.MultiIndex):
            # å¯¹äºå¤šçº§ç´¢å¼•ï¼Œå°†æ‰€æœ‰å±‚çº§çš„åç§°è®¾ç½®ä¸ºNone
            temp_df.columns.names = [None] * temp_df.columns.nlevels
        else:
            # å¯¹äºå•çº§ç´¢å¼•ï¼Œå°†åç§°è®¾ç½®ä¸ºNone
            temp_df.columns.name = None

        result[label] = temp_df

    return result

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# æŒ‰æŒ‡å®šåˆ—å°† DataFrame åˆ†å‰²æˆå¤šä¸ªå­ DataFrameï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªå­—å…¸ä¸­ã€‚
def df_groupby_col(
        df: pd.DataFrame,
        col: str,
        sort_groups: Union[bool, List[Any], Callable, str] = False,
        sort_ascending: bool = True) -> Dict[Any, pd.DataFrame]:
    """
    æŒ‰æŒ‡å®šåˆ—å°† DataFrame åˆ†å‰²æˆå¤šä¸ªå­ DataFrameï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªå­—å…¸ä¸­ã€‚
    æ”¯æŒå¤šç§æ–¹å¼å¯¹åˆ†ç»„è¿›è¡Œæ’åºã€‚

    :param df: DataFrame å¯¹è±¡
    :param col: ç”¨äºåˆ†ç»„çš„åˆ—æ ‡ç­¾
    :param sort_groups: æ§åˆ¶åˆ†ç»„æ’åºçš„æ–¹å¼
        - False: ä¸æ’åºï¼Œä¿æŒåŸå§‹å‡ºç°é¡ºåº (é»˜è®¤)
        - True: æŒ‰ç»„åæ’åº
        - List: æŒ‰æä¾›çš„åˆ—è¡¨é¡ºåºæ’åº
        - Callable: ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°å¯¹ç»„åæ’åº
        - str: æŒ‰æŒ‡å®šåˆ—çš„æ±‡æ€»å€¼æ’åº (å¦‚ 'sum', 'mean', 'count', 'min', 'max', 'std')
    :param sort_ascending: æ’åºé¡ºåºï¼ŒTrue ä¸ºå‡åºï¼ŒFalse ä¸ºé™åº
    :return: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºç»„åï¼Œå€¼ä¸ºå¯¹åº”çš„å­ DataFrameï¼ˆç´¢å¼•å·²é‡ç½®ï¼‰
    """
    # è¾“å…¥æ ¡éªŒ
    if not isinstance(df, pd.DataFrame):
        raise TypeError(f"å‚æ•° 'df' å¿…é¡»æ˜¯ pandas.DataFrameï¼Œå½“å‰ç±»å‹: {type(df).__name__}")
    if col not in df.columns:
        raise KeyError(f"åˆ— '{col}' ä¸å­˜åœ¨äº DataFrame ä¸­ã€‚å¯ç”¨åˆ—: {list(df.columns)}")
    if df.empty:
        return {}

    # ä½¿ç”¨ groupby è·å–åˆ†ç»„ï¼Œsort=False ä¿æŒåŸå§‹é¦–æ¬¡å‡ºç°é¡ºåº
    grouped = df.groupby(col, sort=False)
    groups = {name: group.reset_index(drop=True) for name, group in grouped}

    # è‹¥æ— éœ€æ’åºï¼Œç›´æ¥è¿”å›
    if not sort_groups:
        return groups

    # è·å–æ’åºåçš„é”®åˆ—è¡¨
    if isinstance(sort_groups, list):
        # æŒ‰ç”¨æˆ·æŒ‡å®šåˆ—è¡¨æ’åºï¼Œç¼ºå¤±çš„é”®è¿½åŠ åœ¨æœ«å°¾
        sorted_keys = [k for k in sort_groups if k in groups] + [k for k in groups if k not in sort_groups]
    elif callable(sort_groups):
        # ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°æ’åº
        sorted_keys = sorted(groups.keys(), key=sort_groups, reverse=not sort_ascending)
    elif isinstance(sort_groups, str) and sort_groups in ['sum', 'mean', 'count', 'min', 'max', 'std']:
        # æŒ‰æ•°å€¼åˆ—èšåˆå€¼æ’åºï¼ˆä¼˜å…ˆä½¿ç”¨æ•°å€¼åˆ—ï¼Œé¿å…å¯¹å­—ç¬¦ä¸²åˆ—æ±‚sum/meanï¼‰
        numeric_cols = df.select_dtypes(include=['number']).columns.drop(col, errors='ignore')
        if len(numeric_cols) == 0:
            # æ— æ•°å­—åˆ— â†’ é€€åŒ–ä¸ºæŒ‰é”®åæ’åº
            sorted_keys = sorted(groups.keys(), reverse=not sort_ascending)
        else:
            # å¯¹æ¯ä¸ªåˆ†ç»„çš„æ•°å€¼åˆ—èšåˆåæ±‚å’Œï¼Œä½œä¸ºæ’åºä¾æ®
            agg_series = df.groupby(col)[numeric_cols].agg(sort_groups).sum(axis=1)
            sorted_keys = agg_series.sort_values(ascending=sort_ascending).index.tolist()
    else:
        # sort_groups ä¸º True æˆ–å…¶ä»– Truthy å€¼ â†’ æŒ‰é”®åæ’åº
        sorted_keys = sorted(groups.keys(), reverse=not sort_ascending)

    # æŒ‰æ’åºåçš„é”®é‡å»ºå­—å…¸ï¼ˆPython 3.7+ ä¿æŒæ’å…¥é¡ºåºï¼‰
    return {key: groups[key] for key in sorted_keys}

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# æŒ‰åˆ—ç´¢å¼•åˆ—è¡¨å°† DataFrame åˆ†å‰²æˆå¤šä¸ªå­ DataFrameï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸
def df_split_col(
        df: pd.DataFrame,
        col: List[str],
        include_other: bool = True) -> Dict[str, pd.DataFrame]:
    """
    æŒ‰åˆ—ç´¢å¼•åˆ—è¡¨å°† DataFrame åˆ†å‰²æˆå¤šä¸ªå­ DataFrameï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸

    å‚æ•°:
    -----------
    df : pd.DataFrame
        åŸå§‹æ•°æ®æ¡†ï¼Œå¾…æ‹†åˆ†å¯¹è±¡
    col : List[str]
        éœ€è¦æ‹†åˆ†çš„åˆ—ååˆ—è¡¨
    include_other : bool, å¯é€‰
        æ˜¯å¦åœ¨æ¯ä¸ªå­æ•°æ®æ¡†ä¸­ä¿ç•™â€œéæ‹†åˆ†åˆ—â€çš„å…¶ä»–åˆ—ï¼Œé»˜è®¤ä¸º True

    è¿”å›:
    --------
    Dict[str, pd.DataFrame]
        å­—å…¸ï¼Œé”®ä¸ºæ‹†åˆ†åˆ—åï¼Œå€¼ä¸ºå¯¹åº”çš„å­æ•°æ®æ¡†
    """
    # è¿‡æ»¤å‡ºå®é™…å­˜åœ¨äº DataFrame ä¸­çš„åˆ—
    existing_cols = [c for c in col if c in df.columns]

    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆåˆ—ï¼Œè¿”å›ç©ºå­—å…¸
    if not existing_cols:
        return {}

    # åˆå§‹åŒ–ç»“æœå­—å…¸
    result = {}

    if include_other:
        # è·å–â€œå…¶ä»–åˆ—â€ï¼ˆå³ä¸åœ¨æ‹†åˆ†åˆ—è¡¨ä¸­çš„åˆ—ï¼‰
        other_cols = [c for c in df.columns if c not in col]

        # é¢„å…ˆå¤åˆ¶ä¸€ä»½â€œå…¶ä»–åˆ—â€çš„æ•°æ®æ¡†ï¼Œé¿å…åœ¨å¾ªç¯ä¸­é‡å¤åˆ‡ç‰‡
        other_df = df[other_cols].copy()

        # ä¸ºæ¯ä¸ªå­˜åœ¨çš„æ‹†åˆ†åˆ—åˆ›å»ºå­æ•°æ®æ¡†
        for c in existing_cols:
            # ä½¿ç”¨ assign åŠ¨æ€æ·»åŠ å½“å‰åˆ—ï¼Œé¿å…å¤šæ¬¡å¤åˆ¶â€œå…¶ä»–åˆ—â€æ•°æ®
            result[c] = other_df.assign(**{c: df[c]})
    else:
        # ä»…åŒ…å«æŒ‡å®šçš„å•åˆ—
        for c in existing_cols:
            result[c] = df[[c]].copy()

    return result

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
#ã€€å°†æŒ‡å®šåˆ—çš„æ•°æ®åˆå¹¶ä¸ºæ–°åˆ—ï¼Œå¹¶è¿”å›æ–°DF
def df_comb_cols(
        df: pd.DataFrame,
        cols: List[str],
        name: str,
        combine_func: Union[str, Callable] = 'tuple',
        drop_original: bool = False,
        handle_na: str = 'keep') -> pd.DataFrame:
    '''
    å°†æŒ‡å®šåˆ—çš„æ•°æ®åˆå¹¶ä¸ºæ–°åˆ—ï¼Œå¹¶è¿”å›æ–°DF

    Parameters:
    -----------
    df : pd.DataFrame
        è¾“å…¥çš„æ•°æ®æ¡†ï¼ŒåŒ…å«éœ€è¦å¤„ç†çš„æ•°æ®
    cols : List[str]
        éœ€è¦å¤„ç†çš„åˆ—ååˆ—è¡¨
    name : str
        å¤„ç†åç”Ÿæˆçš„æ–°åˆ—çš„åç§°
    combine_func : Union[str, Callable], optional
        åˆå¹¶å‡½æ•°ï¼Œå¯ä»¥æ˜¯ä»¥ä¸‹é€‰é¡¹ï¼š
        - 'tuple': å°†å€¼ç»„åˆä¸ºå…ƒç»„ (é»˜è®¤)
        - 'list': å°†å€¼ç»„åˆä¸ºåˆ—è¡¨
        - 'str': å°†å€¼ç»„åˆä¸ºå­—ç¬¦ä¸²ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰
        - Callable: è‡ªå®šä¹‰åˆå¹¶å‡½æ•°
    drop_original : bool, optional
        æ˜¯å¦åˆ é™¤åŸå§‹åˆ—ï¼Œé»˜è®¤ä¸ºFalse
    handle_na : str, optional
        å¤„ç†ç©ºå€¼çš„æ–¹å¼ï¼Œå¯ä»¥æ˜¯ä»¥ä¸‹é€‰é¡¹ï¼š
        - 'keep': ä¿ç•™ç©ºå€¼ (é»˜è®¤)
        - 'skip': è·³è¿‡åŒ…å«ç©ºå€¼çš„è¡Œ
        - 'fill': ç”¨æŒ‡å®šå€¼å¡«å……ç©ºå€¼

    Returns:
    --------
    pd.DataFrame
        å¤„ç†åçš„æ•°æ®æ¡†

    Raises:
    -------
    TypeError
        å¦‚æœå‚æ•°ç±»å‹ä¸æ­£ç¡®
    ValueError
        å¦‚æœå‚æ•°å€¼ä¸æ­£ç¡®æˆ–åˆ—ä¸å­˜åœ¨
    '''
    # å‚æ•°éªŒè¯
    if not isinstance(df, pd.DataFrame):
        raise TypeError("dfå¿…é¡»æ˜¯pandas DataFrameç±»å‹")

    if not isinstance(cols, list):
        raise TypeError("colså¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹")

    if not cols:
        raise ValueError("colsä¸èƒ½ä¸ºç©º")

    if not isinstance(name, str) or not name:
        raise ValueError("nameå¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

    if name in df.columns:
        raise ValueError(f"åˆ—å '{name}' å·²å­˜åœ¨äºDataFrameä¸­")

    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    missing_cols = [col for col in cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"åˆ— {missing_cols} åœ¨DataFrameä¸­æœªæ‰¾åˆ°")

    # åˆ›å»ºæ•°æ®å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    result_df = df.copy()

    # å¤„ç†ç©ºå€¼
    if handle_na == 'skip':
        # è·³è¿‡åŒ…å«ç©ºå€¼çš„è¡Œ
        result_df = result_df.dropna(subset=cols)
    elif handle_na == 'fill':
        # ç”¨ç©ºå­—ç¬¦ä¸²å¡«å……ç©ºå€¼
        result_df[cols] = result_df[cols].fillna('')

    # æ ¹æ®combine_funcå‚æ•°é€‰æ‹©åˆå¹¶æ–¹å¼
    if combine_func == 'tuple':
        result_df[name] = list(zip(*[result_df[col] for col in cols]))
    elif combine_func == 'list':
        result_df[name] = [list(x) for x in zip(*[result_df[col] for col in cols])]
    elif combine_func == 'str':
        result_df[name] = [' '.join(map(str, x)) for x in zip(*[result_df[col] for col in cols])]
    elif callable(combine_func):
        result_df[name] = [combine_func(*x) for x in zip(*[result_df[col] for col in cols])]
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„combine_func: {combine_func}")

    # æ˜¯å¦åˆ é™¤åŸå§‹åˆ—
    if drop_original:
        result_df = result_df.drop(columns=cols)

    return result_df

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# å°†æŒ‡å®šåˆ—(cols)ä¸­çš„æ¯ä¸€åˆ—ä¸ç›®æ ‡åˆ—(target_col)ä¸¤ä¸¤ç»„åˆï¼Œå¹¶è¿”å›DataFrameã€‚
def df_pair_cols(
        df: pd.DataFrame,
        cols: List[str],
        target_col: str,
        func: Optional[Callable] = None,
        inplace: bool = False,
        drop_target: bool = False) -> pd.DataFrame:
    """
    å°†æŒ‡å®šåˆ—(cols)ä¸­çš„æ¯ä¸€åˆ—ä¸ç›®æ ‡åˆ—(target_col)ä¸¤ä¸¤ç»„åˆï¼Œå¹¶è¿”å›DataFrameã€‚

    é»˜è®¤æƒ…å†µä¸‹ï¼Œå°†ä¸¤åˆ—å€¼ç»„åˆä¸ºå…ƒç»„ï¼Œä½†å¯ä»¥é€šè¿‡funcå‚æ•°è‡ªå®šä¹‰ç»„åˆæ–¹å¼ã€‚

    :param df: è¾“å…¥çš„pandas DataFrame
    :param cols: éœ€è¦ä¸ç›®æ ‡åˆ—ç»„åˆçš„åˆ—ååˆ—è¡¨
    :param target_col: ç›®æ ‡åˆ—åï¼Œä¸colsä¸­çš„åˆ—è¿›è¡Œç»„åˆ
    :param func: å¯é€‰çš„ç»„åˆå‡½æ•°ï¼Œåº”æ¥å—ä¸¤ä¸ªå‚æ•°å¹¶è¿”å›ä¸€ä¸ªå€¼
                å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„å…ƒç»„ç»„åˆæ–¹å¼
    :param inplace: æ˜¯å¦åŸåœ°ä¿®æ”¹DataFrameï¼Œé»˜è®¤ä¸ºFalse
    :param drop_target: æ˜¯å¦åœ¨ç»„åˆååˆ é™¤ç›®æ ‡åˆ—ï¼Œé»˜è®¤ä¸ºFalse
    :return: å¤„ç†åçš„DataFrame
    :raises TypeError: å¦‚æœå‚æ•°ç±»å‹ä¸æ­£ç¡®
    :raises ValueError: å¦‚æœtarget_colä¸ºç©ºæˆ–ä¸å­˜åœ¨
    """
    # å‚æ•°éªŒè¯
    if not isinstance(df, pd.DataFrame):
        raise TypeError("df å¿…é¡»æ˜¯ pandas DataFrame")

    if not isinstance(cols, list):
        raise TypeError("cols å¿…é¡»æ˜¯åˆ—è¡¨")

    if not isinstance(target_col, str) or not target_col.strip():
        raise ValueError("target_col å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

    if func is not None and not callable(func):
        raise TypeError("func å¿…é¡»æ˜¯å¯è°ƒç”¨å¯¹è±¡æˆ–None")

    # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦å­˜åœ¨
    if target_col not in df.columns:
        raise ValueError(f"ç›®æ ‡åˆ— '{target_col}' åœ¨DataFrameä¸­ä¸å­˜åœ¨")

    # å†³å®šæ˜¯å¦åˆ›å»ºå‰¯æœ¬
    if not inplace:
        df = df.copy()

    # è¿‡æ»¤å‡ºå­˜åœ¨çš„åˆ—
    valid_cols = [col for col in cols if col in df.columns]
    missing_cols = [col for col in cols if col not in df.columns]

    # å‘å‡ºè­¦å‘Šï¼Œæç¤ºç¼ºå¤±çš„åˆ—
    if missing_cols:
        warnings.warn(f"ä»¥ä¸‹åˆ—åœ¨DataFrameä¸­ä¸å­˜åœ¨ï¼Œå°†è¢«è·³è¿‡: {missing_cols}")

    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„åˆ—ï¼Œç›´æ¥è¿”å›
    if not valid_cols:
        warnings.warn("æ²¡æœ‰æœ‰æ•ˆçš„åˆ—éœ€è¦ç»„åˆ")
        return df

    # ç»„åˆåˆ—
    for col in valid_cols:
        if func is None:
            # é»˜è®¤è¡Œä¸ºï¼šå°†ä¸¤åˆ—ç»„åˆä¸ºå…ƒç»„
            df[col] = list(zip(df[col], df[target_col]))
        else:
            # ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°ç»„åˆåˆ—
            df[col] = [func(x, y) for x, y in zip(df[col], df[target_col])]

    # å¦‚æœéœ€è¦ï¼Œåˆ é™¤ç›®æ ‡åˆ—
    if drop_target and target_col in df.columns:
        df.drop(columns=[target_col], inplace=True)

    return df


# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# ç»™ä¸€ä¸ªDataFrameçš„æŸæ­¤åˆ—æ·»åŠ æ’åˆ—ã€‚
def df_add_cols_rank(df: pd.DataFrame, columns_to_rank: list, ascending=False) -> pd.DataFrame:
    """
    ç»™ä¸€ä¸ªDataFrameçš„æŸæ­¤åˆ—æ·»åŠ æ’åˆ—ã€‚

    æ’åä½¿ç”¨ pd.Series.rank() æ–¹æ³•ï¼Œå¯ä»¥å¤„ç† NaN å€¼å’Œå¹¶åˆ—æƒ…å†µã€‚
    é»˜è®¤ä½¿ç”¨é™åºæ’åï¼ˆåˆ†æ•°/æ¯”ç‡è¶Šé«˜ï¼Œæ’åè¶Šé å‰ï¼‰ã€‚

    :param df: è¾“å…¥çš„ pandas DataFrameã€‚
    :param columns_to_rank: éœ€è¦æ·»åŠ æ’åçš„åˆ—æ ‡è¯†åˆ—è¡¨ã€‚å¯ä»¥æ˜¯åˆ—åï¼ˆstrï¼‰æˆ–åˆ—åºå·ï¼ˆintï¼‰çš„åˆ—è¡¨ã€‚
                            ä¾‹å¦‚ ["ratio[60,80)", "mean"] æˆ– [1, 4] æˆ– ["ratio[60,80)", 4]ã€‚
    :param ascending: bool, æ˜¯å¦å‡åºæ’åã€‚False (é»˜è®¤) è¡¨ç¤ºæ•°å€¼è¶Šå¤§æ’åè¶Šé å‰ï¼ˆå¦‚é«˜åˆ†æ’åé å‰ï¼‰ï¼Œ
                      True è¡¨ç¤ºæ•°å€¼è¶Šå°æ’åè¶Šé å‰ï¼ˆå¦‚ä½é”™è¯¯ç‡æ’åé å‰ï¼‰ã€‚
    :return: è¿”å›ä¸€ä¸ªæ–°çš„ DataFrameï¼Œå…¶ä¸­åœ¨æŒ‡å®šåˆ—åæ·»åŠ äº†æ’ååˆ—ã€‚
    """
    # é˜²æ­¢ä¿®æ”¹åŸå§‹ DataFrame
    new_df = df.copy()

    # é¦–å…ˆå°†æ‰€æœ‰è¾“å…¥è½¬æ¢ä¸ºåˆ—å
    resolved_col_names = []
    for item in columns_to_rank:
        if isinstance(item, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½œä¸ºåˆ—å
            if item not in new_df.columns:
                print(f"è­¦å‘Š: æŒ‡å®šçš„åˆ—å '{item}' åœ¨ DataFrame ä¸­ä¸å­˜åœ¨ï¼Œå°†è·³è¿‡ã€‚")
                continue
            resolved_col_names.append(item)
        elif isinstance(item, int):
            # å¦‚æœæ˜¯æ•´æ•°ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åˆ—ç´¢å¼•
            if item < 0:
                item = len(new_df.columns) + item # å¤„ç†è´Ÿç´¢å¼•
            if 0 <= item < len(new_df.columns):
                col_name = new_df.columns[item]
                resolved_col_names.append(col_name)
            else:
                print(f"è­¦å‘Š: æŒ‡å®šçš„åˆ—åºå· {item} è¶…å‡ºèŒƒå›´ [0, {len(new_df.columns)-1}]ï¼Œå°†è·³è¿‡ã€‚")
                continue
        else:
            print(f"è­¦å‘Š: åˆ—æ ‡è¯† '{item}' ç±»å‹æ— æ•ˆ (åº”ä¸º str æˆ– int)ï¼Œå°†è·³è¿‡ã€‚")
            continue

    # ä»åå¾€å‰éå†ï¼Œä»¥é¿å…åˆ—ç´¢å¼•å› æ’å…¥æ–°åˆ—è€Œå˜åŒ–
    for col_name in reversed(resolved_col_names):
        source_series = new_df[col_name]

        # è®¡ç®—æ’å
        # method='min' è¡¨ç¤ºå¹¶åˆ—é¡¹ç›®å–æœ€å°æ’å (ä¾‹å¦‚ï¼Œä¸¤ä¸ªç¬¬ä¸€ï¼Œåˆ™ä¸‹ä¸€ä¸ªä¸ºç¬¬ä¸‰)
        # na_option='keep' è¡¨ç¤º NaN å€¼æ’åä¸º NaN
        # ascending=False è¡¨ç¤ºæ•°å€¼å¤§çš„æ’åé å‰ (1, 2, 3...)
        ranks = source_series.rank(method='min', na_option='keep', ascending=ascending)

        # æ‰¾åˆ°æºåˆ—çš„ç´¢å¼•ä½ç½®
        source_col_idx = new_df.columns.get_loc(col_name)

        # å°†æ’ååˆ—æ’å…¥åˆ°æºåˆ—ä¹‹å
        rank_col_name = f"{col_name}_rank"
        new_df.insert(loc=source_col_idx + 1, column=rank_col_name, value=ranks)

    return new_df





# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# åˆå¹¶å¤šä¸ªDataFrameï¼Œå¤„ç†é‡å¤åˆ—åå¹¶æä¾›è¯¦ç»†çš„è­¦å‘Šå’Œé”™è¯¯ä¿¡æ¯ã€‚
def merge_mult_dfs(
        dfs: List[pd.DataFrame],
        on: Union[str, List[str]],
        how: str = 'outer',
        keep_last: bool = True) -> pd.DataFrame:
    """
    åˆå¹¶å¤šä¸ªDataFrameï¼Œå¤„ç†é‡å¤åˆ—åå¹¶æä¾›è¯¦ç»†çš„è­¦å‘Šå’Œé”™è¯¯ä¿¡æ¯ã€‚

    å‚æ•°:
    dfs: DataFrameåˆ—è¡¨ï¼Œéœ€è¦åˆå¹¶çš„æ‰€æœ‰DataFrame
    on: å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼Œåˆå¹¶çš„é”®åˆ—
    how: åˆå¹¶æ–¹å¼ï¼Œå¯é€‰ 'left', 'right', 'outer', 'inner'ï¼Œé»˜è®¤ä¸º'outer'
    keep_last: å¸ƒå°”å€¼ï¼Œå½“æœ‰é‡å¤åˆ—æ—¶æ˜¯å¦ä¿ç•™æœ€åä¸€ä¸ªDataFrameçš„å€¼ï¼Œé»˜è®¤ä¸ºTrue

    è¿”å›:
    åˆå¹¶åçš„DataFrame

    å¼‚å¸¸:
    ValueError: å½“è¾“å…¥å‚æ•°æ— æ•ˆæˆ–DataFrameç¼ºå°‘å¿…è¦çš„é”®åˆ—æ—¶
    TypeError: å½“è¾“å…¥å‚æ•°ç±»å‹ä¸æ­£ç¡®æ—¶

    è­¦å‘Š:
    - å½“åˆå¹¶é”®çš„æ•°æ®ç±»å‹ä¸ä¸€è‡´æ—¶
    - å½“æœ‰é‡å¤åˆ—éœ€è¦å¤„ç†æ—¶
    - å½“åˆå¹¶å¯èƒ½äº§ç”Ÿæ„å¤–ç»“æœæ—¶ï¼ˆå¦‚how='left'æˆ–how='right'ï¼‰
    """
    # éªŒè¯è¾“å…¥
    if not dfs:
        warnings.warn("æä¾›çš„DataFrameåˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ç©ºDataFrame")
        return pd.DataFrame()

    if not isinstance(dfs, list):
        raise TypeError("dfs å¿…é¡»æ˜¯DataFrameåˆ—è¡¨")

    if len(dfs) == 1:
        warnings.warn("åªæä¾›äº†ä¸€ä¸ªDataFrameï¼Œç›´æ¥è¿”å›å…¶å‰¯æœ¬")
        return dfs[0].copy()

    # ç¡®ä¿onæ˜¯åˆ—è¡¨å½¢å¼
    if isinstance(on, str):
        on_keys = [on]
    else:
        on_keys = list(on)  # ç¡®ä¿æ˜¯å¯å˜çš„åˆ—è¡¨

    # éªŒè¯æ‰€æœ‰DataFrameéƒ½åŒ…å«å¿…è¦çš„é”®åˆ—
    for i, df in enumerate(dfs):
        if not isinstance(df, pd.DataFrame):
            raise TypeError(f"dfs[{i}] ä¸æ˜¯pandas DataFrame")

        missing_keys = [key for key in on_keys if key not in df.columns]
        if missing_keys:
            raise ValueError(f"DataFrame {i} ç¼ºå°‘é”®åˆ—: {missing_keys}")

    # æ£€æŸ¥åˆå¹¶é”®çš„æ•°æ®ç±»å‹ä¸€è‡´æ€§
    for key in on_keys:
        dtypes = []
        for i, df in enumerate(dfs):
            dtype = str(df[key].dtype)
            dtypes.append((i, dtype))

        # æ£€æŸ¥æ‰€æœ‰DataFrameä¸­åŒä¸€é”®çš„æ•°æ®ç±»å‹æ˜¯å¦ä¸€è‡´
        unique_dtypes = set(dtype for _, dtype in dtypes)
        if len(unique_dtypes) > 1:
            dtype_info = ", ".join([f"df{i}: {dtype}" for i, dtype in dtypes])
            warnings.warn(
                f"åˆå¹¶é”® '{key}' çš„æ•°æ®ç±»å‹åœ¨ä¸åŒDataFrameä¸­ä¸ä¸€è‡´: {dtype_info}. "
                "è¿™å¯èƒ½å¯¼è‡´åˆå¹¶é”™è¯¯æˆ–æ„å¤–ç»“æœã€‚"
            )

    # ä½¿ç”¨reduceé€æ­¥åˆå¹¶
    def merge_two_dfs(df_left, df_right):
        # æ‰¾å‡ºé™¤äº†è¿æ¥é”®ä»¥å¤–çš„é‡å¤åˆ—å
        common_cols = df_left.columns.intersection(df_right.columns)
        common_cols = common_cols.difference(on_keys)

        # å‘å‡ºé‡å¤åˆ—è­¦å‘Š
        if not common_cols.empty:
            warnings.warn(
                f"å‘ç°é‡å¤åˆ—: {list(common_cols)}. "
                f"{'ä¿ç•™æœ€åä¸€ä¸ªDataFrameçš„å€¼' if keep_last else 'ä¿ç•™ç¬¬ä¸€ä¸ªDataFrameçš„å€¼'}"
            )

        # å¦‚æœæ²¡æœ‰é‡å¤åˆ—ï¼Œç›´æ¥åˆå¹¶
        if common_cols.empty:
            return pd.merge(df_left, df_right, how=how, on=on_keys)

        # ä½¿ç”¨é»˜è®¤çš„é‡å‘½åç­–ç•¥å¤„ç†é‡å¤åˆ—
        suffix = '_temp'
        rename_dict = {col: col + suffix for col in common_cols}
        df_left_renamed = df_left.rename(columns=rename_dict)

        # åˆå¹¶DataFrame
        merged = pd.merge(df_left_renamed, df_right, how=how, on=on_keys)

        # å¤„ç†é‡å¤åˆ—
        for col in common_cols:
            temp_col = col + suffix
            if keep_last:
                # ä¿ç•™æœ€åä¸€ä¸ªDataFrameçš„å€¼
                merged[col] = merged[col].combine_first(merged[temp_col])
            else:
                # ä¿ç•™ç¬¬ä¸€ä¸ªDataFrameçš„å€¼
                merged[col] = merged[temp_col].combine_first(merged[col])
            merged.drop(columns=[temp_col], inplace=True)

        return merged

    # å‘å‡ºå…³äºåˆå¹¶æ–¹å¼çš„è­¦å‘Š
    if how in ['left', 'right']:
        warnings.warn(
            f"ä½¿ç”¨ how='{how}' æ—¶ï¼Œåˆå¹¶ç»“æœå¯èƒ½å—DataFrameé¡ºåºå½±å“ã€‚"
            "è€ƒè™‘ä½¿ç”¨ how='outer' æˆ– how='inner' ä»¥è·å¾—æ›´å¯é¢„æµ‹çš„ç»“æœã€‚"
        )

    # ä½¿ç”¨reduceé€æ­¥åˆå¹¶æ‰€æœ‰DataFrame
    try:
        result = functools.reduce(merge_two_dfs, dfs)

        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
        if result.empty:
            warnings.warn("åˆå¹¶åçš„DataFrameä¸ºç©ºã€‚è¯·æ£€æŸ¥åˆå¹¶é”®å’Œåˆå¹¶æ–¹å¼ã€‚")

        return result
    except Exception as e:
        raise ValueError(f"åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}") from e

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# å°†DataFrameçš„åˆ—ç´¢å¼•æŒ‰æŒ‡å®šåˆ—è¡¨é¡ºåºæ’åºï¼Œç„¶åæŒ‰æŒ‡å®šåˆ—å¯¹æ•°æ®è¿›è¡Œæ’åº
def df_sort(
        df: pd.DataFrame,
        cols: Optional[List[str]] = None,
        sort_by: Union[str, List[str]] = 'A',
        ascending: Union[bool, List[bool]] = True,
        na_position: str = 'last',
        keep_extra_cols: bool = True,
        inplace: bool = False) -> pd.DataFrame:
    """
    å°†DataFrameçš„åˆ—ç´¢å¼•æŒ‰æŒ‡å®šåˆ—è¡¨é¡ºåºæ’åºï¼Œç„¶åæŒ‰æŒ‡å®šåˆ—å¯¹æ•°æ®è¿›è¡Œæ’åº

    å‚æ•°:
    df: è¦æ’åºçš„pandas DataFrame
    cols: åˆ—é¡ºåºåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneï¼Œåˆ™ä¿æŒåŸæœ‰åˆ—é¡ºåº
    sort_by: ç”¨äºè¡Œæ’åºçš„åˆ—åæˆ–åˆ—ååˆ—è¡¨ï¼Œé»˜è®¤ä¸º'A'
    ascending: æ’åºæ–¹å‘ï¼ŒTrueä¸ºå‡åºï¼ŒFalseä¸ºé™åº
                å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåˆ™å¯¹åº”æ¯ä¸ªæ’åºåˆ—çš„æ’åºæ–¹å‘
    na_position: ç¼ºå¤±å€¼çš„ä½ç½®ï¼Œ'first'æˆ–'last'ï¼Œé»˜è®¤ä¸º'last'
    keep_extra_cols: å½“ä¸ºTrueæ—¶ï¼Œä¸åœ¨colsåˆ—è¡¨ä¸­çš„åˆ—ä¹ŸåŒ…æ‹¬åœ¨ç»“æœä¸­ï¼›
                     å½“ä¸ºFalseæ—¶ï¼Œä¸åœ¨colsåˆ—è¡¨ä¸­çš„åˆ—ä¸åŒ…æ‹¬åœ¨ç»“æœä¸­ï¼ˆè¢«ä¸¢å¼ƒï¼‰
    inplace: æ˜¯å¦åŸåœ°ä¿®æ”¹DataFrameï¼Œé»˜è®¤ä¸ºFalse

    è¿”å›:
    æ’åºåçš„DataFrame

    å¼‚å¸¸:
    ValueError: å½“å‚æ•°å€¼æ— æ•ˆæ—¶
    TypeError: å½“å‚æ•°ç±»å‹ä¸æ­£ç¡®æ—¶
    """
    # å‚æ•°éªŒè¯
    if not isinstance(df, pd.DataFrame):
        raise TypeError("df å¿…é¡»æ˜¯pandas DataFrame")

    if cols is not None and not isinstance(cols, list):
        raise TypeError("cols å¿…é¡»æ˜¯åˆ—è¡¨æˆ–None")

    if not isinstance(keep_extra_cols, bool):
        raise TypeError("keep_extra_cols å¿…é¡»æ˜¯å¸ƒå°”å€¼")

    if na_position not in ['first', 'last']:
        raise ValueError("na_position å¿…é¡»æ˜¯ 'first' æˆ– 'last'")

    # æ£€æŸ¥æ’åºåˆ—æ˜¯å¦å­˜åœ¨
    if isinstance(sort_by, str):
        sort_columns = [sort_by]
    else:
        sort_columns = list(sort_by)

    missing_sort_cols = [col for col in sort_columns if col not in df.columns]
    if missing_sort_cols:
        raise ValueError(f"DataFrameä¸­ç¼ºå°‘æ’åºåˆ—: {missing_sort_cols}")

    # å†³å®šæ˜¯å¦åˆ›å»ºå‰¯æœ¬
    if not inplace:
        df = df.copy()

    # å¤„ç†åˆ—æ’åº
    if cols is not None:
        # æ£€æŸ¥colsä¸­æ˜¯å¦åŒ…å«ä¸å­˜åœ¨çš„åˆ—
        extra_cols = [col for col in cols if col not in df.columns]
        if extra_cols:
            warnings.warn(f"colsä¸­åŒ…å«DataFrameä¸­ä¸å­˜åœ¨çš„åˆ—: {extra_cols}")

        # è·å–å­˜åœ¨çš„åˆ—
        existing_cols = [col for col in cols if col in df.columns]

        # ç¡®å®šæœ€ç»ˆåˆ—é¡ºåº
        if keep_extra_cols:
            # ä¿ç•™ä¸åœ¨colsä¸­çš„åˆ—ï¼Œæ”¾åœ¨æŒ‡å®šåˆ—åé¢
            other_cols = [col for col in df.columns if col not in existing_cols]
            final_cols = existing_cols + other_cols
        else:
            # åªä¿ç•™colsä¸­å­˜åœ¨çš„åˆ—ï¼Œä¸¢å¼ƒä¸åœ¨colsä¸­çš„åˆ—
            final_cols = existing_cols

        # é‡æ–°æ’åˆ—åˆ—
        df = df[final_cols]

    # æŒ‰æŒ‡å®šåˆ—æ’åº
    df = df.sort_values(
        by=sort_columns,
        ascending=ascending,
        na_position=na_position
    )

    # é‡ç½®ç´¢å¼•ï¼ˆå¯é€‰ï¼Œä½†é€šå¸¸æ’åºåä¼šé‡ç½®ç´¢å¼•ï¼‰
    df.reset_index(drop=True, inplace=True)

    return df

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# å¯¹DataFrameä¸­æŒ‡å®šåˆ—è¿›è¡Œæ’åï¼Œè¿”å›å½¢çŠ¶ç›¸åŒçš„DataFrame
def df_rank_cols(
        df: pd.DataFrame,
        cols: List[str],
        method: Literal['min', 'max', 'average', 'first', 'dense'] = 'min',
        ascending: bool = True,
        na_option: Literal['keep', 'top', 'bottom'] = 'keep'    ) -> pd.DataFrame:
        """
        å¯¹DataFrameä¸­æŒ‡å®šåˆ—è¿›è¡Œæ’åï¼Œè¿”å›å½¢çŠ¶ç›¸åŒçš„DataFrame

        å‚æ•°:
        df (pd.DataFrame): è¾“å…¥çš„DataFrame
        cols (list): éœ€è¦æ’åçš„åˆ—ååˆ—è¡¨
        method (str): æ’åæ–¹æ³• ('min', 'max', 'average', 'first', 'dense')
        ascending (bool): æ˜¯å¦å‡åºæ’åˆ—ï¼ˆTrue: å°å€¼æ’åé å‰ï¼ŒFalse: å¤§å€¼æ’åé å‰ï¼‰
        na_option (str): NaNå¤„ç†æ–¹å¼ ('keep', 'top', 'bottom')
            - 'keep': ä¿ç•™åŸå§‹NaNå€¼ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
            - 'top': å°†NaNè§†ä¸ºæœ€å°å€¼ï¼ˆæ’å1ï¼‰
            - 'bottom': å°†NaNè§†ä¸ºæœ€å¤§å€¼ï¼ˆæ’åæœ€åï¼‰

        è¿”å›:
        pd.DataFrame: æŒ‡å®šåˆ—è¢«æ›¿æ¢ä¸ºæ’ååçš„å€¼ï¼Œå…¶ä»–åˆ—ä¿æŒä¸å˜

        ä¸ºä»€ä¹ˆæ²¡æœ‰"è§†ä¸º0"çš„é€‰é¡¹ï¼Ÿ
        --------------------------------------------------------
        1. æ’åé€»è¾‘ä»1å¼€å§‹ï¼Œ0ä¸æ˜¯æœ‰æ•ˆæ’åå€¼
           ä¾‹å¦‚ï¼š[1, 2, NaN] çš„æ’ååº”ä¸º [1, 2, ?]ï¼Œä¸æ˜¯ [1, 2, 0]

        2. pandasåŸç”Ÿrank()å‡½æ•°ä¸æ”¯æŒ"0"é€‰é¡¹
           pandasçš„rank()æ–¹æ³•ä»…æ”¯æŒ:
              na_option='keep' (é»˜è®¤)
              na_option='top'
              na_option='bottom'

        3. "è§†ä¸º0"ä¼šç ´åæ’åé€»è¾‘
           - æ’åè¡¨ç¤º"ä½ç½®"ï¼ˆ1=æœ€é«˜/æœ€ä½ï¼Œ2=æ¬¡é«˜/æ¬¡ä½...ï¼‰
           - 0åœ¨æ’åä¸­æ²¡æœ‰æ„ä¹‰ï¼ˆæ’åä»1å¼€å§‹ï¼‰

        4. æ­£ç¡®åšæ³•ï¼šå…ˆæ’åï¼Œå†å¤„ç†NaN
           # æ’ååå°†NaNæ›¿æ¢ä¸º0ï¼ˆä»…å½“éœ€è¦æ—¶ï¼‰
           result = df_rank_cols(df, cols)
           result = result.fillna(0)
        """
        df_ranked = df.copy()
        for col in cols:
            df_ranked[col] = df_ranked[col].rank(
                method=method,
                ascending=ascending,
                na_option=na_option
            )
        return df_ranked

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# ä¸º DataFrame æ·»åŠ ä¸‰åˆ—ï¼šè¡Œå’Œã€ç‚¹ç§¯ã€ç‚¹ç§¯æ’åï¼ˆæ”¯æŒå·¦å³ä½ç½®æ§åˆ¶ï¼‰
def df_add_rank(
        df: pd.DataFrame,
        lst: Optional[List[Union[int, float]]] = None,
        sum_col_name: str = "è¡Œå’Œ",
        dot_col_name: str = "ç‚¹ç§¯",
        rank_col_name: str = "ç‚¹ç§¯æ’å",
        direction: Literal['first', 'last'] = 'first',
        position: Literal['left', 'right'] = 'left'    ) -> pd.DataFrame:
    """
    ä¸º DataFrame æ·»åŠ ä¸‰åˆ—ï¼šè¡Œå’Œã€ç‚¹ç§¯ã€ç‚¹ç§¯æ’åï¼ˆæ”¯æŒå·¦å³ä½ç½®æ§åˆ¶ï¼‰

    åŠŸèƒ½ï¼š
      - ä»æ•°å€¼åˆ—ä¸­æŒ‰æ–¹å‘ï¼ˆå‰/åï¼‰é€‰ len(lst) ä¸ªåˆ—
      - è®¡ç®—ï¼šè¡Œå’Œã€ç‚¹ç§¯ï¼ˆåŠ æƒå’Œï¼‰ã€ç‚¹ç§¯é™åºæ’å
      - å¯é€‰å°†ä¸‰åˆ—ç½®äºæœ€å·¦æˆ–æœ€å³

    å‚æ•°ï¼š
      df: è¾“å…¥ DataFrame
      sum_col_name: è¡Œå’Œåˆ—å
      dot_col_name: ç‚¹ç§¯åˆ—å
      rank_col_name: æ’ååˆ—å
      lst: æƒé‡åˆ—è¡¨ï¼Œé•¿åº¦å†³å®šå‚ä¸è®¡ç®—åˆ—æ•°ï¼ˆNone â†’ å…¨ NaNï¼‰
      direction: 'first'ï¼ˆå‰ï¼‰æˆ– 'last'ï¼ˆåï¼‰
      position: 'left' æˆ– 'right'

    è¿”å›ï¼š
      æ–°å¢ä¸‰åˆ—çš„ DataFrameï¼ˆä¸ä¿®æ”¹åŸæ•°æ®ï¼‰
    """

    # ========== 1. å‚æ•°éªŒè¯ ==========
    if not isinstance(df, pd.DataFrame):
        raise TypeError("df å¿…é¡»æ˜¯ pandas.DataFrame")

    if lst is not None and not isinstance(lst, list):
        raise TypeError("lst å¿…é¡»æ˜¯åˆ—è¡¨æˆ– None")

    # ========== 2. åˆ›å»ºå‰¯æœ¬å¹¶æå–æ•°å€¼åˆ— ==========
    df = df.copy()
    numeric_df = df.select_dtypes(include=[np.number])

    if numeric_df.empty:
        # ç›´æ¥åˆ›å»ºä¸‰åˆ— NaN å¹¶è¿”å›
        return _add_nan_cols_and_reorder(df, [sum_col_name, dot_col_name, rank_col_name], position)

    numeric_columns = numeric_df.columns.tolist()
    n_numeric = len(numeric_columns)

    # ========== 3. å¤„ç†ç‰¹æ®Š lst æƒ…å†µ ==========
    if lst is None:
        return _add_nan_cols_and_reorder(df, [sum_col_name, dot_col_name, rank_col_name], position)

    if not lst:  # ç©ºåˆ—è¡¨
        return _add_zero_cols_and_reorder(df, [sum_col_name, dot_col_name, rank_col_name], position)

    # ========== 4. é€‰æ‹©å‚ä¸è®¡ç®—çš„åˆ— ==========
    n_weights = len(lst)

    if n_weights > n_numeric:
        # è‡ªåŠ¨è°ƒæ•´æƒé‡åˆ—è¡¨é•¿åº¦
        lst = lst[:n_numeric]
        selected_columns = numeric_columns
    else:
        selected_columns = (
            numeric_columns[:n_weights] if direction == 'first'
            else numeric_columns[-n_weights:]
        )

    # ========== 5. å‘é‡åŒ–è®¡ç®— ==========
    selected_data = df[selected_columns]
    weights_array = np.array(lst)

    # ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è¡Œ
    row_sums = selected_data.sum(axis=1)
    dot_products = selected_data.dot(weights_array)

    # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ’åæ–¹æ³•
    dot_ranks = dot_products.rank(method='dense', ascending=False).astype(int)

    # ========== 6. æ·»åŠ åˆ—å¹¶è°ƒæ•´é¡ºåº ==========
    df[sum_col_name] = row_sums
    df[dot_col_name] = dot_products
    df[rank_col_name] = dot_ranks
    return _move_cols(df, [sum_col_name, dot_col_name, rank_col_name], position)

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
def _add_nan_cols_and_reorder(df: pd.DataFrame, col_names: List[str], position: str) -> pd.DataFrame:
    """å¿«é€Ÿæ·»åŠ  NaN åˆ—å¹¶é‡æ’åº"""
    for col in col_names:
        df[col] = np.nan
    return _move_cols(df, col_names, position)

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
def _add_zero_cols_and_reorder(df: pd.DataFrame, col_names: List[str], position: str) -> pd.DataFrame:
    """å¿«é€Ÿæ·»åŠ é›¶å€¼åˆ—å¹¶é‡æ’åº"""
    n_rows = len(df)
    df[col_names[0]] = 0.0  # è¡Œæ€»å’Œ
    df[col_names[1]] = 0.0  # ç‚¹ç§¯
    df[col_names[2]] = 1  # æ’åï¼ˆå…¨éƒ¨ä¸º1ï¼‰
    return _move_cols(df, col_names, position)

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
def _move_cols(df: pd.DataFrame, target_cols: List[str], pos: Literal['left', 'right']) -> pd.DataFrame:
    """å°†æŒ‡å®šåˆ—ç§»åŠ¨åˆ°æœ€å·¦æˆ–æœ€å³ï¼Œå…¶ä½™åˆ—ä¿æŒåŸé¡ºåº"""
    existing_cols = [col for col in target_cols if col in df.columns]
    other_cols = [col for col in df.columns if col not in existing_cols]

    new_order = existing_cols + other_cols if pos == 'left' else other_cols + existing_cols
    return df[new_order]


# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–   å°è£…ä¸ºbytesIO/zip  â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# æŠŠä¸€ä¸ª df å°è£…ä¸ºä¸€ä¸ªäºŒè¿›è¿›åˆ¶çš„BytesIOå¯¹è±¡ã€‚
def df_to_bytesIO(df):
    """
    å°†ä¸€ä¸ªPandas DataFrameå¯¹è±¡å°è£…ä¸ºä¸€ä¸ªäºŒè¿›åˆ¶çš„BytesIOå¯¹è±¡ã€‚

    :param df: Pandas DataFrameå¯¹è±¡
    :return: ä¸€ä¸ªåŒ…å«Excelæ•°æ®çš„äºŒè¿›åˆ¶BytesIOå¯¹è±¡
    """
    if not isinstance(df, pd.DataFrame):
        raise ValueError("df å¿…é¡»æ˜¯Pandas DataFrameå¯¹è±¡")

    # åˆ›å»ºBytesIOå¯¹è±¡
    bio_file = BytesIO()

    # ä½¿ç”¨ExcelWriterå°†DataFrameå†™å…¥BytesIOå¯¹è±¡
    with pd.ExcelWriter(bio_file, engine='openpyxl') as writer:
        df.to_excel(writer, index=False)  # index=Falseè¡¨ç¤ºä¸åŒ…å«è¡Œç´¢å¼•

    # ç¡®ä¿æŒ‡é’ˆä½äºæ–‡ä»¶çš„å¼€å¤´
    bio_file.seek(0)
    return bio_file

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# æŠŠä¸€ä¸ª openpyxl ç”Ÿæˆçš„ workbook å°è£…ä¸ºä¸€ä¸ªäºŒè¿›è¿›åˆ¶çš„ BytesIO å¯¹è±¡ã€‚
def wb_to_bytesIO(wb):
    """
    æŠŠä¸€ä¸ª openpyxl ç”Ÿæˆçš„ workbook å¯¹è±¡å°è£…ä¸ºä¸€ä¸ªäºŒè¿›åˆ¶çš„ BytesIO å¯¹è±¡ã€‚

    :param wb: ç”± openpyxl ç”Ÿæˆçš„ workbook å¯¹è±¡
    :return: ä¸€ä¸ªäºŒè¿›åˆ¶çš„ BytesIO å¯¹è±¡
    """
    if not isinstance(wb, openpyxl.Workbook):
        raise ValueError("wb å¿…é¡»æ˜¯ openpyxl ç”Ÿæˆçš„ Workbook å¯¹è±¡")

    bio_file = BytesIO()
    wb.save(bio_file)
    bio_file.seek(0)  # ç¡®ä¿æŒ‡é’ˆä½äºæ–‡ä»¶çš„å¼€å¤´
    return bio_file

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# å¤šä¸ªDataFrameä¿å­˜åˆ°å†…å­˜ä¸­çš„ZIPæ–‡ä»¶,ä»¥æä¾›ç»™ä¸‹è½½æŒ‰é’®
def dfs_to_zip(
        dfs_dic: Dict[str, pd.DataFrame],
        format: str = 'excel',
        empty_msg: str = 'ç©ºå€¼') -> BytesIO:
    """
    å°†å¤šä¸ªDataFrameä¿å­˜åˆ°å†…å­˜ä¸­çš„ZIPæ–‡ä»¶

    Parameters:
    -----------
    dfs_dic : dict
        åŒ…å«DataFrameçš„å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    format : str, optional
        è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒ'excel'ï¼ˆé»˜è®¤ï¼‰æˆ–'csv'
    empty_msg : str, optional
        ç©ºDataFrameæ—¶æ˜¾ç¤ºçš„æ¶ˆæ¯ï¼Œé»˜è®¤ä¸º'ç©ºå€¼'

    Returns:
    --------
    BytesIO
        åŒ…å«ZIPæ–‡ä»¶å†…å®¹çš„å­—èŠ‚ç¼“å†²åŒº

    Raises:
    -------
    ValueError
        å¦‚æœæŒ‡å®šçš„æ ¼å¼ä¸è¢«æ”¯æŒ
    """
    # éªŒè¯æ ¼å¼å‚æ•°
    if format not in ('excel', 'csv'):
        raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}. æ”¯æŒ 'excel' æˆ– 'csv'")

    # åˆ›å»ºå†…å­˜ä¸­çš„ZIPæ–‡ä»¶
    bio_zip = BytesIO()

    try:
        with zipfile.ZipFile(bio_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for name, df in dfs_dic.items():
                # æ£€æŸ¥DataFrameæ˜¯å¦ä¸ºç©º
                if df.empty:
                    df = pd.DataFrame({'æç¤º': [empty_msg]})

                # å®‰å…¨å¤„ç†æ–‡ä»¶å
                safe_name = _sanitize_filename(str(name) if name is not None else 'data')

                # æ ¹æ®æ ¼å¼å¤„ç†æ•°æ®
                if format == 'excel':
                    file_data = _df_to_excel(df, safe_name)
                    file_ext = 'xlsx'
                else:  # csv
                    file_data = _df_to_csv(df)
                    file_ext = 'csv'

                # å°†æ–‡ä»¶æ•°æ®å†™å…¥ZIP
                zipf.writestr(f'{safe_name}.{file_ext}', file_data)

    except Exception as e:
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä½†å…ˆç¡®ä¿ç¼“å†²åŒºè¢«é‡ç½®
        bio_zip.seek(0)
        bio_zip.truncate(0)
        raise e

    # å°†æŒ‡é’ˆé‡ç½®åˆ°ç¼“å†²åŒºå¼€å¤´
    bio_zip.seek(0)
    return bio_zip

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# åˆ›å»ºä¸€ä¸ªå®‰å…¨å¤„ç†æ–‡ä»¶åçš„å‡½æ•°
def _sanitize_filename(
        name: str,
        max_length: int = 30) -> str:
    """
    å®‰å…¨å¤„ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦å¹¶é™åˆ¶é•¿åº¦

    Parameters:
    -----------
    name : str
        åŸå§‹æ–‡ä»¶å
    max_length : int, optional
        æœ€å¤§é•¿åº¦é™åˆ¶ï¼Œé»˜è®¤ä¸º30

    Returns:
    --------
    str
        å¤„ç†åçš„å®‰å…¨æ–‡ä»¶å
    """
    # ç§»é™¤éASCIIå­—ç¬¦å’Œéæ³•æ–‡ä»¶åå­—ç¬¦
    safe_name = re.sub(r'[^\w\s-]', '', name).strip()

    # æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
    safe_name = re.sub(r'[-\s]+', '_', safe_name)

    # é™åˆ¶é•¿åº¦
    if len(safe_name) > max_length:
        safe_name = safe_name[:max_length]

    # å¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨é»˜è®¤åç§°
    if not safe_name:
        safe_name = 'data'

    return safe_name

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# åˆ›å»ºä¸€ä¸ªå°†DataFrameè½¬æ¢ä¸ºExcelå­—èŠ‚æ•°æ®çš„å‡½æ•°
def _df_to_excel(
        df: pd.DataFrame,
        sheet_name: str) -> bytes:
    """
    å°†DataFrameè½¬æ¢ä¸ºExcelå­—èŠ‚æ•°æ®

    Parameters:
    -----------
    df : pd.DataFrame
        è¦è½¬æ¢çš„DataFrame
    sheet_name : str
        Excelå·¥ä½œè¡¨åç§°

    Returns:
    --------
    bytes
        Excelæ–‡ä»¶çš„å­—èŠ‚æ•°æ®
    """
    excel_buffer = BytesIO()

    try:
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name=sheet_name[:31], index=False)  # Excelé™åˆ¶å·¥ä½œè¡¨å31å­—ç¬¦
        return excel_buffer.getvalue()
    finally:
        excel_buffer.close()

# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
#ã€€åˆ›å»ºä¸€ä¸ªå°†DataFrameè½¬æ¢ä¸ºCSVå­—èŠ‚æ•°æ®çš„å‡½æ•°
def _df_to_csv(
        df: pd.DataFrame) -> bytes:
    """
    å°†DataFrameè½¬æ¢ä¸ºCSVå­—èŠ‚æ•°æ®

    Parameters:
    -----------
    df : pd.DataFrame
        è¦è½¬æ¢çš„DataFrame

    Returns:
    --------
    bytes
        CSVæ–‡ä»¶çš„å­—èŠ‚æ•°æ®ï¼ˆUTF-8ç¼–ç ï¼‰
    """
    csv_buffer = BytesIO()

    try:
        # ä½¿ç”¨UTF-8ç¼–ç ç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        return csv_buffer.getvalue()
    finally:
        csv_buffer.close()


# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–     å­—å…¸ç›¸å…³çš„å‡½æ•°  â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
# å°†å­—å…¸çš„é”®å€¼åè½¬ï¼Œå¹¶æŒ‰ç…§æŒ‡å®šçš„é¡ºåºå¯¹åè½¬åçš„é”®è¿›è¡Œæ’åºã€‚
def dict_rev_sort(
        dic: Dict[Any, List[str]],
        sort_order: List[str],
        keep_all_keys: bool = False,
        default_value: Any = None    ) -> Dict[str, Any]:
    """
    å°†å­—å…¸çš„é”®å€¼åè½¬ï¼Œå¹¶æŒ‰ç…§æŒ‡å®šçš„é¡ºåºå¯¹åè½¬åçš„é”®è¿›è¡Œæ’åºã€‚

    å‚æ•°:
        dic: åŸå§‹å­—å…¸ï¼Œé”®ä¸ºä»»æ„ç±»å‹ï¼Œå€¼ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
        sort_order: æŒ‡å®šé”®çš„æ’åºé¡ºåºåˆ—è¡¨
        keep_all_keys: æ˜¯å¦ä¿ç•™æ‰€æœ‰é”®ï¼ˆåŒ…æ‹¬ä¸åœ¨sort_orderä¸­çš„é”®ï¼‰
        default_value: å¯¹äºä¸åœ¨sort_orderä¸­çš„é”®ï¼Œä½¿ç”¨çš„é»˜è®¤å€¼ï¼ˆå½“keep_all_keysä¸ºFalseæ—¶ä½¿ç”¨ï¼‰

    è¿”å›:
        åè½¬å¹¶æ’åºåçš„å­—å…¸ï¼Œé”®ä¸ºåŸå§‹å­—å…¸å€¼ä¸­çš„å­—ç¬¦ä¸²ï¼Œå€¼ä¸ºåŸå§‹å­—å…¸çš„é”®

    å¼‚å¸¸:
        ValueError: å½“sort_orderä¸ºç©ºæˆ–dicä¸ºç©ºæ—¶
        TypeError: å½“å‚æ•°ç±»å‹ä¸æ­£ç¡®æ—¶
    """
    # å‚æ•°éªŒè¯
    if not dic:
        raise ValueError("dic ä¸èƒ½ä¸ºç©º")

    if not sort_order:
        raise ValueError("sort_order ä¸èƒ½ä¸ºç©º")

    if not isinstance(dic, dict):
        raise TypeError("dic å¿…é¡»æ˜¯å­—å…¸ç±»å‹")

    if not isinstance(sort_order, list):
        raise TypeError("sort_order å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹")

    # åè½¬å­—å…¸
    reversed_dict = {}
    for key, value_list in dic.items():
        if not isinstance(value_list, list):
            raise TypeError(f"dic çš„å€¼å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹ï¼Œä½† {key} çš„å€¼æ˜¯ {type(value_list)}")

        for item in value_list:
            reversed_dict[item] = key

    # æŒ‰ç…§æŒ‡å®šçš„é¡ºåºåˆ›å»ºæ–°å­—å…¸
    sorted_dict = {}
    for item in sort_order:
        if item in reversed_dict:
            sorted_dict[item] = reversed_dict[item]
        elif not keep_all_keys and default_value is not None:
            sorted_dict[item] = default_value

    # æ·»åŠ å¯èƒ½ä¸åœ¨sort_orderä¸­çš„é”®ï¼ˆå¦‚æœkeep_all_keysä¸ºTrueï¼‰
    if keep_all_keys:
        for item, value in reversed_dict.items():
            if item not in sorted_dict:
                sorted_dict[item] = value

    return sorted_dict